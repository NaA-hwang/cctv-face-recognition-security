# src/extract_frames_from_video.py
# ì˜ìƒì—ì„œ íŠ¹ì • ì¸ë¬¼(hani ë“±)ì„ ì‹ë³„í•˜ì—¬ ì–¼êµ´ì„ ì¶”ì¶œí•˜ëŠ” ë„êµ¬
# ì˜†ì–¼êµ´ ë“± ë‹¤ì–‘í•œ ê°ë„ì˜ ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í•˜ì—¬ bankì— ì¶”ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©

import cv2
import numpy as np
from pathlib import Path
from insightface.app import FaceAnalysis
from utils.device_config import get_device_id, safe_prepare_insightface, _ensure_cuda_in_path
from utils.gallery_loader import load_gallery, match_with_bank

_ensure_cuda_in_path()


def extract_frames(video_path: Path, output_dir: Path, frame_indices: list[int] = None, 
                   extract_all: bool = False, interval: int = 1):
    """
    ì˜ìƒì—ì„œ í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì—¬ ì €ì¥
    
    Args:
        video_path: ì…ë ¥ ì˜ìƒ ê²½ë¡œ (GIF, MP4 ë“±)
        output_dir: í”„ë ˆì„ ì €ì¥ ë””ë ‰í† ë¦¬
        frame_indices: ì¶”ì¶œí•  íŠ¹ì • í”„ë ˆì„ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: [10, 20, 30])
        extract_all: Trueë©´ ëª¨ë“  í”„ë ˆì„ ì¶”ì¶œ
        interval: extract_all=Trueì¼ ë•Œ í”„ë ˆì„ ê°„ê²©
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise FileNotFoundError(f"ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŒ: {video_path}")
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    print(f"ğŸ“¹ ì˜ìƒ ì •ë³´: {video_path.name}")
    print(f"   ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
    
    saved_count = 0
    frame_idx = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        should_save = False
        
        if extract_all:
            if frame_idx % interval == 0:
                should_save = True
        elif frame_indices and frame_idx in frame_indices:
            should_save = True
        
        if should_save:
            out_path = output_dir / f"frame_{frame_idx:05d}.jpg"
            cv2.imwrite(str(out_path), frame)
            saved_count += 1
            print(f"  ğŸ’¾ í”„ë ˆì„ {frame_idx} ì €ì¥: {out_path.name}")
        
        frame_idx += 1
    
    cap.release()
    print(f"\nâœ… ì´ {saved_count}ê°œ í”„ë ˆì„ ì €ì¥ ì™„ë£Œ: {output_dir}")


def extract_faces_from_frames(video_path: Path, output_dir: Path, person_id: str,
                              frame_indices: list[int] = None, min_face_size: int = 50,
                              use_imageio: bool = True, match_threshold: float = 0.30,
                              emb_dir: Path = None):
    """
    ì˜ìƒì—ì„œ íŠ¹ì • ì¸ë¬¼ì„ ì‹ë³„í•˜ì—¬ ì–¼êµ´ì„ ì¶”ì¶œí•˜ì—¬ ì €ì¥
    ì˜†ì–¼êµ´ ë“± ë‹¤ì–‘í•œ ê°ë„ì˜ ì–¼êµ´ì„ ìˆ˜ì§‘í•˜ê¸° ìœ„í•´ ì‚¬ìš©
    
    Args:
        video_path: ì…ë ¥ ì˜ìƒ ê²½ë¡œ
        output_dir: ì–¼êµ´ ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ (person_id í´ë” ìƒì„±)
        person_id: ì‹ë³„í•  ì‚¬ëŒ ID (ê°¤ëŸ¬ë¦¬ì—ì„œ ë§¤ì¹­)
        frame_indices: ì¶”ì¶œí•  í”„ë ˆì„ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  í”„ë ˆì„)
        min_face_size: ìµœì†Œ ì–¼êµ´ í¬ê¸° (í”½ì…€)
        use_imageio: Trueë©´ imageio ì‚¬ìš© (GIFì— ê¶Œì¥), Falseë©´ cv2.VideoCapture ì‚¬ìš©
        match_threshold: ë§¤ì¹­ ì„ê³„ê°’ (ì´ ê°’ ì´ìƒì´ë©´ í•´ë‹¹ ì¸ë¬¼ë¡œ ì¸ì‹)
        emb_dir: ì„ë² ë”© ë””ë ‰í† ë¦¬ (Noneì´ë©´ outputs/embeddings ì‚¬ìš©)
    """
    # ê°¤ëŸ¬ë¦¬ ë¡œë“œ (ì¸ë¬¼ ì‹ë³„ìš©)
    if emb_dir is None:
        emb_dir = Path("outputs") / "embeddings"
    gallery = load_gallery(emb_dir, use_bank=True)
    
    if person_id not in gallery:
        raise RuntimeError(f"âŒ ê°¤ëŸ¬ë¦¬ì— {person_id}ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë“±ë¡í•´ì£¼ì„¸ìš”.")
    
    print(f"ğŸ‘¤ ëŒ€ìƒ ì¸ë¬¼: {person_id}")
    if gallery[person_id].ndim == 2:
        print(f"   Bank ì„ë² ë”©: {gallery[person_id].shape[0]}ê°œ")
    else:
        print(f"   Centroid ì„ë² ë”© ì‚¬ìš©")
    print(f"   ë§¤ì¹­ ì„ê³„ê°’: {match_threshold}")
    
    # InsightFace ì´ˆê¸°í™”
    device_id = get_device_id()
    device_type = "GPU" if device_id >= 0 else "CPU"
    print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {device_type} (ctx_id={device_id})")
    
    app = FaceAnalysis(name="buffalo_l")
    actual_device_id = safe_prepare_insightface(app, device_id, det_size=(640, 640))
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    person_dir = output_dir / person_id
    person_dir.mkdir(parents=True, exist_ok=True)
    
    # GIFëŠ” imageio ì‚¬ìš© ê¶Œì¥
    if use_imageio and video_path.suffix.lower() in ['.gif', '.gifv']:
        import imageio.v2 as imageio
        frames = imageio.mimread(str(video_path))
        total_frames = len(frames)
        print(f"ğŸ“¹ ì˜ìƒ ë¶„ì„ ì‹œì‘: {video_path.name} (imageio ì‚¬ìš©)")
        print(f"   ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
        print(f"   ì €ì¥ ê²½ë¡œ: {person_dir}")
        
        if frame_indices:
            # ë²”ìœ„ ì²´í¬
            valid_indices = [idx for idx in frame_indices if 0 <= idx < total_frames]
            invalid_indices = [idx for idx in frame_indices if idx < 0 or idx >= total_frames]
            if invalid_indices:
                print(f"   âš ï¸ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ í”„ë ˆì„ ë²ˆí˜¸: {invalid_indices}")
            if valid_indices:
                print(f"   ì²˜ë¦¬í•  í”„ë ˆì„: {valid_indices}")
            else:
                print(f"   âŒ ìœ íš¨í•œ í”„ë ˆì„ ë²ˆí˜¸ê°€ ì—†ìŠµë‹ˆë‹¤!")
                return
        else:
            valid_indices = list(range(total_frames))
        
        saved_count = 0
        
        for frame_idx in valid_indices:
            frame_rgb = frames[frame_idx]
            # RGB â†’ BGR ë³€í™˜
            if frame_rgb.ndim == 2:
                frame = cv2.cvtColor(frame_rgb, cv2.COLOR_GRAY2BGR)
            elif frame_rgb.shape[2] == 4:
                frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGBA2BGR)
            else:
                frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)
            
            faces = app.get(frame)
            print(f"[í”„ë ˆì„ {frame_idx}] ê°ì§€ëœ ì–¼êµ´: {len(faces)}ê°œ")
            
            if len(faces) > 0:
                # ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
                faces_sorted = sorted(
                    faces,
                    key=lambda f: (f.bbox[2] - f.bbox[0]) * (f.bbox[3] - f.bbox[1]),
                    reverse=True
                )
                main_face = faces_sorted[0]
                
                # ì–¼êµ´ í¬ê¸° ì²´í¬
                face_w = main_face.bbox[2] - main_face.bbox[0]
                face_h = main_face.bbox[3] - main_face.bbox[1]
                
                print(f"  â†’ ê°€ì¥ í° ì–¼êµ´ í¬ê¸°: {face_w:.0f}x{face_h:.0f} (ìµœì†Œ: {min_face_size})")
                
                if face_w >= min_face_size and face_h >= min_face_size:
                    # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ (ì•½ê°„ì˜ ì—¬ìœ  ê³µê°„ ì¶”ê°€)
                    x1, y1, x2, y2 = map(int, main_face.bbox)
                    margin = 20
                    x1 = max(0, x1 - margin)
                    y1 = max(0, y1 - margin)
                    x2 = min(frame.shape[1], x2 + margin)
                    y2 = min(frame.shape[0], y2 + margin)
                    
                    face_img = frame[y1:y2, x1:x2]
                    
                    # ì €ì¥
                    out_path = person_dir / f"{person_id}_f{frame_idx:05d}.jpg"
                    cv2.imwrite(str(out_path), face_img)
                    saved_count += 1
                    
                    print(f"  âœ… ì–¼êµ´ ì¶”ì¶œ ì™„ë£Œ â†’ {out_path.name}")
                else:
                    print(f"  â­ ìŠ¤í‚µ: ì–¼êµ´ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ ({face_w:.0f}x{face_h:.0f} < {min_face_size})")
            else:
                print(f"  âš ï¸ ì–¼êµ´ì„ ì°¾ì§€ ëª»í•¨")
        
        print(f"\nâœ… ì´ {saved_count}ê°œ ì–¼êµ´ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {person_dir}")
        
    else:
        # cv2.VideoCapture ì‚¬ìš© (MP4 ë“±)
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            raise FileNotFoundError(f"ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŒ: {video_path}")
        
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        print(f"ğŸ“¹ ì˜ìƒ ë¶„ì„ ì‹œì‘: {video_path.name}")
        print(f"   ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
        print(f"   ì €ì¥ ê²½ë¡œ: {person_dir}")
        
        saved_count = 0
        frame_idx = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # íŠ¹ì • í”„ë ˆì„ë§Œ ì²˜ë¦¬
            if frame_indices and frame_idx not in frame_indices:
                frame_idx += 1
                continue
            
            faces = app.get(frame)
            print(f"[í”„ë ˆì„ {frame_idx}] ê°ì§€ëœ ì–¼êµ´: {len(faces)}ê°œ")
            
            if len(faces) > 0:
                # ê° ì–¼êµ´ì„ ê°¤ëŸ¬ë¦¬ì™€ ë¹„êµí•˜ì—¬ í•´ë‹¹ ì¸ë¬¼ì¸ì§€ í™•ì¸
                matched_faces = []
                
                for face in faces:
                    face_emb = face.embedding.astype("float32")
                    best_person, best_sim = match_with_bank(face_emb, gallery)
                    
                    # í•´ë‹¹ ì¸ë¬¼ì´ê³  ì„ê³„ê°’ ì´ìƒì´ë©´ ìˆ˜ì§‘ ëŒ€ìƒ
                    if best_person == person_id and best_sim >= match_threshold:
                        face_w = face.bbox[2] - face.bbox[0]
                        face_h = face.bbox[3] - face.bbox[1]
                        
                        if face_w >= min_face_size and face_h >= min_face_size:
                            matched_faces.append({
                                "face": face,
                                "sim": best_sim,
                                "size": (face_w, face_h)
                            })
                
                # ë§¤ì¹­ëœ ì–¼êµ´ì´ ìˆìœ¼ë©´ ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
                if matched_faces:
                    # ìœ ì‚¬ë„ê°€ ë†’ê³  í¬ê¸°ë„ í° ìˆœìœ¼ë¡œ ì •ë ¬
                    matched_faces.sort(key=lambda x: (x["sim"], x["size"][0] * x["size"][1]), reverse=True)
                    best_match = matched_faces[0]
                    main_face = best_match["face"]
                    best_sim = best_match["sim"]
                    face_w, face_h = best_match["size"]
                    
                    print(f"  â†’ {person_id} ë§¤ì¹­! sim={best_sim:.3f}, í¬ê¸°={face_w:.0f}x{face_h:.0f}")
                    
                    # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ (ì•½ê°„ì˜ ì—¬ìœ  ê³µê°„ ì¶”ê°€)
                    x1, y1, x2, y2 = map(int, main_face.bbox)
                    margin = 20
                    x1 = max(0, x1 - margin)
                    y1 = max(0, y1 - margin)
                    x2 = min(frame.shape[1], x2 + margin)
                    y2 = min(frame.shape[0], y2 + margin)
                    
                    face_img = frame[y1:y2, x1:x2]
                    
                    # ì €ì¥
                    out_path = person_dir / f"{person_id}_f{frame_idx:05d}_sim{best_sim:.2f}.jpg"
                    cv2.imwrite(str(out_path), face_img)
                    saved_count += 1
                    
                    print(f"  âœ… ì–¼êµ´ ì¶”ì¶œ ì™„ë£Œ â†’ {out_path.name}")
                else:
                    # ë§¤ì¹­ëœ ì–¼êµ´ì´ ì—†ìœ¼ë©´ ëª¨ë“  ì–¼êµ´ì˜ ë§¤ì¹­ ê²°ê³¼ ì¶œë ¥
                    for face in faces:
                        face_emb = face.embedding.astype("float32")
                        best_person, best_sim = match_with_bank(face_emb, gallery)
                        print(f"  â†’ ë§¤ì¹­: {best_person} (sim={best_sim:.3f}) - {person_id} ì•„ë‹˜")
            else:
                print(f"  âš ï¸ ì–¼êµ´ì„ ì°¾ì§€ ëª»í•¨")
            
            frame_idx += 1
        
        cap.release()
        print(f"\nâœ… ì´ {saved_count}ê°œ ì–¼êµ´ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {person_dir}")


def main():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    # ì„¤ì •
    video_path = Path("images") / "newjeans_dance.gif"
    output_dir = Path("images") / "extracted_frames"
    person_id = "hani"  # ì¶”ì¶œí•  ì‚¬ëŒ ID
    
    # ë°©ë²• 1: íŠ¹ì • í”„ë ˆì„ ë²ˆí˜¸ ì§€ì • (ì˜†ì–¼êµ´ì´ ë³´ì´ëŠ” í”„ë ˆì„)
    # ì˜ˆ: í”„ë ˆì„ 50, 60, 70ì—ì„œ ì˜†ì–¼êµ´ì´ ë³´ì¸ë‹¤ë©´
    # frame_indices = [50, 60, 70, 80, 90]  # ì—¬ê¸°ì— ì˜†ì–¼êµ´ í”„ë ˆì„ ë²ˆí˜¸ ì…ë ¥
    
    # ë°©ë²• 2: Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ëª¨ë“  í”„ë ˆì„ì—ì„œ ì–¼êµ´ ì¶”ì¶œ (ë” ë§ì€ ì˜µì…˜)
    frame_indices = None  # ëª¨ë“  í”„ë ˆì„ ì²˜ë¦¬
    
    # ë˜ëŠ” íŠ¹ì • ë²”ìœ„ë§Œ ì²˜ë¦¬
    # frame_indices = list(range(0, 73))  # 0~72 í”„ë ˆì„ ëª¨ë‘
    
    print("=" * 60)
    print("ì˜ìƒì—ì„œ ì–¼êµ´ í”„ë ˆì„ ì¶”ì¶œ ë„êµ¬")
    print("=" * 60)
    print(f"ì˜ìƒ: {video_path}")
    print(f"ëŒ€ìƒ: {person_id}")
    if frame_indices:
        print(f"í”„ë ˆì„ ë²ˆí˜¸: {frame_indices}")
    else:
        print(f"í”„ë ˆì„ ë²ˆí˜¸: ëª¨ë“  í”„ë ˆì„")
    print()
    
    # ì–¼êµ´ ì¶”ì¶œ ì‹¤í–‰ (GIFëŠ” imageio ì‚¬ìš©)
    extract_faces_from_frames(
        video_path=video_path,
        output_dir=output_dir,
        person_id=person_id,
        frame_indices=frame_indices,
        min_face_size=30,  # ìµœì†Œ í¬ê¸°ë¥¼ ë‚®ì¶°ì„œ ë” ë§ì€ ì–¼êµ´ ìˆ˜ì§‘
        use_imageio=True,  # GIFëŠ” imageio ì‚¬ìš© ê¶Œì¥
        match_threshold=0.30,  # ì´ ê°’ ì´ìƒì´ë©´ í•´ë‹¹ ì¸ë¬¼ë¡œ ì¸ì‹
        emb_dir=Path("outputs") / "embeddings"  # ì„ë² ë”© ë””ë ‰í† ë¦¬
    )
    
    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"1. {output_dir / person_id} í´ë”ì—ì„œ ì¶”ì¶œëœ ì´ë¯¸ì§€ í™•ì¸")
    print("2. ì˜†ì–¼êµ´ ì´ë¯¸ì§€ë“¤ì„ ì„ íƒí•˜ì—¬ images/enroll/{person_id}/ í´ë”ë¡œ ë³µì‚¬")
    print("3. python src/face_enroll_bank.py ì‹¤í–‰í•˜ì—¬ bank ì—…ë°ì´íŠ¸")
    print("   ë˜ëŠ” python src/add_embeddings_to_bank.py ì‹¤í–‰í•˜ì—¬ ì§ì ‘ bankì— ì¶”ê°€")


if __name__ == "__main__":
    main()

