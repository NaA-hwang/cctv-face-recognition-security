# src/face_match_video_tracks.py
# CUDA ê²½ë¡œë¥¼ ë¨¼ì € ì„¤ì • (ê°€ì¥ ë¨¼ì € import)
from utils.device_config import _ensure_cuda_in_path
_ensure_cuda_in_path()

from insightface.app import FaceAnalysis
import cv2
import numpy as np
from pathlib import Path
import imageio.v2 as imageio
import time
from collections import defaultdict
from utils.gallery_loader import load_gallery, match_with_bank
from utils.device_config import get_device_id, safe_prepare_insightface

# -------------------------------
# ìœ í‹¸ í•¨ìˆ˜ë“¤
# -------------------------------

def iou(boxA, boxB):
    # box: [x1, y1, x2, y2]
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[2], boxB[2])
    yB = min(boxA[3], boxB[3])

    inter_w = max(0, xB - xA)
    inter_h = max(0, yB - yA)
    inter = inter_w * inter_h

    if inter == 0:
        return 0.0

    areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])
    areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])

    return inter / float(areaA + areaB - inter + 1e-6)

# -------------------------------
# ë©”ì¸ ë¡œì§
# -------------------------------

def main():
    # 1) ê°¤ëŸ¬ë¦¬ ë¡œë“œ (bank ìš°ì„ )
    emb_dir = Path("outputs") / "embeddings"
    gallery = load_gallery(emb_dir, use_bank=True)
    print("ğŸ‘¥ ê°¤ëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ:", list(gallery.keys()))
    # Bank ì‚¬ìš© ì—¬ë¶€ í™•ì¸
    for pid, data in gallery.items():
        if data.ndim == 2:
            print(f"  - {pid}: bank ({data.shape[0]}ê°œ ì„ë² ë”©)")
        else:
            print(f"  - {pid}: centroid")

    # 2) InsightFace ì´ˆê¸°í™” (GPU ìš°ì„ , ì—†ìœ¼ë©´ CPU)
    device_id = get_device_id()
    device_type = "GPU" if device_id >= 0 else "CPU"
    print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {device_type} (ctx_id={device_id})")
    
    app = FaceAnalysis(name="buffalo_l")
    actual_device_id = safe_prepare_insightface(app, device_id, det_size=(640, 640))
    if actual_device_id != device_id:
        print(f"   (ì‹¤ì œ ì‚¬ìš©: {'GPU' if actual_device_id >= 0 else 'CPU'})")
    print("set det-size: (640, 640)")

    # 3) ì…ë ¥ ì˜ìƒ (GIF / mp4 ìƒê´€ ì—†ìŒ)
    video_path = Path("images") / "newjeans_dance.gif"
    frames = imageio.mimread(str(video_path))
    total_frames = len(frames)
    print(f"ğŸ¥ ì˜ìƒ ë¶„ì„ ì‹œì‘: {video_path}  (í”„ë ˆì„ ìˆ˜: {total_frames})")

    # ---------------------------
    # Track êµ¬ì¡°:
    # track_id: {
    #   'person': ì¶”ì • ì¸ë¬¼ëª…,
    #   'detections': [ {frame, bbox, sim}, ... ],
    #   'last_bbox': [...],
    #   'last_frame': int
    # }
    # ---------------------------
    tracks = {}
    next_track_id = 0    
    
    # ---------------------------
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° (ìë™ ëª¨ë“œ)
    # ---------------------------
    MODE = "test"   # ğŸ”§ ì—¬ê¸°ì„œ "test" <-> "prod" ë°”ê¿” ì“°ë©´ ë¨

    if MODE == "test":
        # ğŸ‘‰ ì‹¤í—˜ìš©: ì¡°ê¸ˆ ëŠìŠ¨í•˜ê²Œ
        BASE_THRESH   = 0.25   # ì´ ê°’ ì´ìƒì´ë©´ "ì´ ì‚¬ëŒì¼ ê°€ëŠ¥ì„± ìˆìŒ"
        STRONG_THRESH = 0.35   # íŠ¸ë™ í™•ì • ì„ê³„ê°’
        MIN_TRACK_LEN = 3      # ìµœì†Œ ê°ì§€ íšŸìˆ˜
        IOU_THRESH    = 0.3    # íŠ¸ë˜í‚¹ IoU ê¸°ì¤€
        MAX_SKIP      = 5      # ëª‡ í”„ë ˆì„ê¹Œì§€ ëŠê¸°ì§€ ì•Šì€ ê²ƒìœ¼ë¡œ ë³¼ì§€
    else:  # MODE == "prod"
        # ğŸ‘‰ ì‹¤ì œ CCTVì— ê°€ê¹ê²Œ: ë” ì—„ê²©í•˜ê²Œ
        BASE_THRESH   = 0.30
        STRONG_THRESH = 0.45
        MIN_TRACK_LEN = 5
        IOU_THRESH    = 0.4
        MAX_SKIP      = 3

    print(f"\nâš™ MODE = {MODE}")
    print(f"   BASE_THRESH   = {BASE_THRESH}")
    print(f"   STRONG_THRESH = {STRONG_THRESH}")
    print(f"   MIN_TRACK_LEN = {MIN_TRACK_LEN}")
    print(f"   IOU_THRESH    = {IOU_THRESH}")
    print(f"   MAX_SKIP      = {MAX_SKIP}\n")
    

    t0 = time.time()

    for f_idx, frame in enumerate(frames):
        # imageioê°€ ë„˜ê²¨ì¤€ frameì„ numpy ë°°ì—´ë¡œ ë³´ì¥
        frame = np.array(frame)

        # ì±„ë„ ìˆ˜ì— ë”°ë¼ BGR 3ì±„ë„ë¡œ ë³€í™˜
        if frame.ndim == 2:
            # í‘ë°± â†’ BGR
            img = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
        elif frame.shape[2] == 4:
            # RGBA â†’ BGR
            img = cv2.cvtColor(frame, cv2.COLOR_RGBA2BGR)
        else:
            # RGB â†’ BGR
            img = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

        faces = app.get(img)
        print(f"[frame {f_idx}] faces: {len(faces)}")

        detections = []
        for face in faces:
            emb = face.embedding.astype("float32")
            
            # Bank ê¸°ë°˜ ë§¤ì¹­ (ë˜ëŠ” centroid)
            best_person, best_sim = match_with_bank(emb, gallery)

            bbox = list(map(int, face.bbox))
            detections.append({
                "person": best_person,
                "sim": best_sim,
                "bbox": bbox,
                "embedding": emb / (np.linalg.norm(emb) + 1e-6)  # Online Learningì„ ìœ„í•´ ì €ì¥
            })
            print(f"  -> det person={best_person}, sim={best_sim:.3f}")

        # ---------------------------
        # ë°ì´í„° ì—°ê³„ (Tracking)
        # ---------------------------
        # ê° detectionì„ ê¸°ì¡´ trackì— ë¶™ì´ê±°ë‚˜ ìƒˆ íŠ¸ë™ ìƒì„±
        for det in detections:
            if det["sim"] < BASE_THRESH:
                # ë„ˆë¬´ ë‚®ìœ¼ë©´ ì•„ì˜ˆ íŠ¸ë™ì— ì•ˆ ë¶™ì„ (unknown ì·¨ê¸‰)
                continue

            assigned_tid = None
            best_iou = 0.0

            for tid, tr in tracks.items():
                # ê°™ì€ ì‚¬ëŒì´ê³ , í”„ë ˆì„ ì°¨ì´ê°€ ë„ˆë¬´ í¬ì§€ ì•Šì„ ë•Œë§Œ í›„ë³´
                if tr["person"] != det["person"]:
                    continue
                if f_idx - tr["last_frame"] > MAX_SKIP:
                    continue

                iou_val = iou(tr["last_bbox"], det["bbox"])
                if iou_val > IOU_THRESH and iou_val > best_iou:
                    best_iou = iou_val
                    assigned_tid = tid

            if assigned_tid is None:
                # ìƒˆ íŠ¸ë™ ìƒì„±
                tid = next_track_id
                next_track_id += 1
                tracks[tid] = {
                    "person": det["person"],
                    "detections": [],
                    "last_bbox": det["bbox"],
                    "last_frame": f_idx
                }
                assigned_tid = tid
            else:
                # ê¸°ì¡´ íŠ¸ë™ ê°±ì‹ 
                tracks[assigned_tid]["last_bbox"] = det["bbox"]
                tracks[assigned_tid]["last_frame"] = f_idx

            # ê³µí†µ: detection ê¸°ë¡ ì¶”ê°€
            tracks[assigned_tid]["detections"].append({
                "frame": f_idx,
                "bbox": det["bbox"],
                "sim": det["sim"]
            })

    # ---------------------------
    # íŠ¸ë™ë³„ ìš”ì•½ & ìŠ¤ëƒ…ìƒ· ì €ì¥
    # ---------------------------
    matches_dir = Path("outputs") / "tracks"
    matches_dir.mkdir(parents=True, exist_ok=True)

    # ìŠ¤ëƒ…ìƒ·ì„ ìœ„í•´ í”„ë ˆì„ ë‹¤ì‹œ ë¡œë“œ (ë©”ëª¨ë¦¬ ì•„ë¼ë ¤ë©´ ì²˜ìŒë¶€í„° ì €ì¥í•´ë„ ë¨)
    frames = imageio.mimread(str(video_path))

    print("\n===== íŠ¸ë™ ìš”ì•½ =====")
    for tid, tr in tracks.items():
        person = tr["person"]
        sims = [d["sim"] for d in tr["detections"]]
        max_sim = max(sims)
        avg_sim = sum(sims) / len(sims)
        length = len(tr["detections"])

        print(f"[track {tid}] person={person}, length={length}, "
              f"avg_sim={avg_sim:.3f}, max_sim={max_sim:.3f}")

        # ì¶©ë¶„íˆ ê¸¸ê³ , max simì´ STRONG_THRESH ì´ìƒì´ë©´ "í™•ì‹¤í•œ íŠ¸ë™"ìœ¼ë¡œ ê°„ì£¼
        if length >= MIN_TRACK_LEN and max_sim >= STRONG_THRESH:
            # ìµœê³  simì´ ë‚˜ì˜¨ í”„ë ˆì„ì˜ bboxë¡œ ìŠ¤ëƒ…ìƒ· ì €ì¥
            best_det = max(tr["detections"], key=lambda d: d["sim"])
            f_idx = best_det["frame"]
            x1, y1, x2, y2 = best_det["bbox"]

            img = frames[f_idx].copy()
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            label = f"{person} {max_sim:.2f}"
            cv2.putText(img, label, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            out_name = f"{person}_track{tid}_best.jpg"
            cv2.imwrite(str(matches_dir / out_name), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))
            print(f"  -> âœ… í™•ì • íŠ¸ë™, ìŠ¤ëƒ…ìƒ· ì €ì¥: {out_name}")
            
            # Online Learning: Bankì— ì„ë² ë”© ì¶”ê°€
            bank_path = emb_dir / f"{person}_bank.npy"
            if bank_path.exists() and "embedding" in best_det:
                best_emb = best_det["embedding"]
                
                # Bank ë¡œë“œ
                bank = np.load(bank_path)  # (N, 512)
                
                # ì¤‘ë³µ ì²´í¬: ê¸°ì¡´ bankì™€ ë„ˆë¬´ ìœ ì‚¬í•œ ì„ë² ë”©ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ
                if bank.ndim == 2 and bank.shape[0] > 0:
                    max_existing_sim = float(np.max(bank @ best_emb))
                    if max_existing_sim < 0.95:  # ê±°ì˜ ë™ì¼í•œ ì„ë² ë”©ì´ ì•„ë‹ˆë©´ ì¶”ê°€
                        bank = np.vstack([bank, best_emb.reshape(1, -1)])
                        np.save(bank_path, bank)
                        print(f"  -> ğŸ“š Bank ì—…ë°ì´íŠ¸: {person}_bank.npy ({bank.shape[0]}ê°œ ì„ë² ë”©)")
                    else:
                        print(f"  -> (Bank ì—…ë°ì´íŠ¸ ìŠ¤í‚µ: ìœ ì‚¬ ì„ë² ë”© ì¡´ì¬, sim={max_existing_sim:.3f})")
                else:
                    # Bankê°€ ë¹„ì–´ìˆê±°ë‚˜ í˜•ì‹ì´ ì´ìƒí•œ ê²½ìš°
                    bank = best_emb.reshape(1, -1)
                    np.save(bank_path, bank)
                    print(f"  -> ğŸ“š Bank ìƒì„±/ì—…ë°ì´íŠ¸: {person}_bank.npy")
        else:
            print("  -> (ìŠ¤ëƒ…ìƒ· ì €ì¥ ì•ˆ í•¨: ê¸¸ì´ or sim ë¶€ì¡±)")

    t1 = time.time()
    print(f"\nâœ… ì „ì²´ ë¶„ì„ ì™„ë£Œ, ì†Œìš”ì‹œê°„: {t1 - t0:.2f}ì´ˆ, ì´ íŠ¸ë™ ìˆ˜: {len(tracks)}")

if __name__ == "__main__":
    main()
