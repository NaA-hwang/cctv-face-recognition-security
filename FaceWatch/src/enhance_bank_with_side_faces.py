# src/enhance_bank_with_side_faces.py
# ì˜ìƒì—ì„œ ì˜†ì–¼êµ´ ë“± ë‹¤ì–‘í•œ ê°ë„ì˜ ì–¼êµ´ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ bankì— ì¶”ê°€í•˜ëŠ” í†µí•© ë„êµ¬

from insightface.app import FaceAnalysis
import cv2
import numpy as np
from pathlib import Path
import imageio.v2 as imageio
from utils.device_config import get_device_id, safe_prepare_insightface, _ensure_cuda_in_path
from utils.gallery_loader import load_gallery, match_with_bank

_ensure_cuda_in_path()


def l2_normalize(vec: np.ndarray) -> np.ndarray:
    """ë²¡í„°ë¥¼ L2 ì •ê·œí™”"""
    norm = np.linalg.norm(vec)
    if norm == 0:
        return vec
    return vec / norm


def estimate_face_angle(face) -> str:
    """
    ì–¼êµ´ ê°ë„ë¥¼ ëŒ€ëµì ìœ¼ë¡œ ì¶”ì • (ëœë“œë§ˆí¬ ê¸°ë°˜)
    
    Returns:
        "front", "left", "right", "profile" ë“±
    """
    if not hasattr(face, 'kps') or face.kps is None:
        return "unknown"
    
    # ê°„ë‹¨í•œ ì¶”ì •: ì½”ì™€ ëˆˆì˜ ìœ„ì¹˜ë¡œ íŒë‹¨
    # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê³„ì‚°ì´ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ì ì¸ ì˜ˆì‹œë§Œ ì œê³µ
    return "front"  # ê¸°ë³¸ê°’


def find_diverse_faces_in_video(video_path: Path, person_id: str, gallery: dict,
                                emb_dir: Path, app: FaceAnalysis,
                                match_threshold: float = 0.30,
                                similarity_threshold: float = 0.90,
                                max_faces_per_person: int = 10):
    """
    ì˜ìƒì—ì„œ íŠ¹ì • ì¸ë¬¼ì˜ ë‹¤ì–‘í•œ ê°ë„ ì–¼êµ´ì„ ì°¾ì•„ bankì— ì¶”ê°€
    
    Args:
        video_path: ë¶„ì„í•  ì˜ìƒ ê²½ë¡œ
        person_id: ì°¾ì„ ì‚¬ëŒ ID
        gallery: ê°¤ëŸ¬ë¦¬ ë”•ì…”ë„ˆë¦¬
        emb_dir: ì„ë² ë”© ì €ì¥ ë””ë ‰í† ë¦¬
        app: FaceAnalysis ì¸ìŠ¤í„´ìŠ¤
        match_threshold: ë§¤ì¹­ ì„ê³„ê°’ (ì´ ê°’ ì´ìƒì´ë©´ í•´ë‹¹ ì¸ë¬¼ë¡œ ì¸ì‹)
        similarity_threshold: bankì— ì¶”ê°€í•  ë•Œ ì¤‘ë³µ ì²´í¬ ì„ê³„ê°’
        max_faces_per_person: ì¸ë¬¼ë‹¹ ìµœëŒ€ ì¶”ê°€í•  ì–¼êµ´ ìˆ˜
    
    Returns:
        ì¶”ê°€ëœ ì–¼êµ´ ê°œìˆ˜
    """
    if person_id not in gallery:
        print(f"âŒ ê°¤ëŸ¬ë¦¬ì— {person_id}ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0
    
    print(f"ğŸ¥ ì˜ìƒ ë¶„ì„ ì‹œì‘: {video_path.name}")
    print(f"   ëŒ€ìƒ ì¸ë¬¼: {person_id}")
    print(f"   ë§¤ì¹­ ì„ê³„ê°’: {match_threshold}")
    print(f"   ì¤‘ë³µ ì²´í¬ ì„ê³„ê°’: {similarity_threshold}")
    print()
    
    # ì˜ìƒ ë¡œë“œ
    frames = imageio.mimread(str(video_path))
    total_frames = len(frames)
    print(f"   ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
    
    # ê¸°ì¡´ bank ë¡œë“œ
    bank_path = emb_dir / f"{person_id}_bank.npy"
    if bank_path.exists():
        bank = np.load(bank_path)
        print(f"ğŸ“š ê¸°ì¡´ bank: {bank.shape[0]}ê°œ ì„ë² ë”©")
    else:
        bank = np.empty((0, 512), dtype=np.float32)
        print(f"ğŸ“š ìƒˆ bank ìƒì„±")
    
    # ìˆ˜ì§‘ëœ ì–¼êµ´ ì„ë² ë”©
    collected_embeddings = []
    frame_info = []
    
    # ê° í”„ë ˆì„ ë¶„ì„
    for f_idx, frame in enumerate(frames):
        # RGB â†’ BGR ë³€í™˜
        if frame.ndim == 2:
            img = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
        elif frame.shape[2] == 4:
            img = cv2.cvtColor(frame, cv2.COLOR_RGBA2BGR)
        else:
            img = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        
        faces = app.get(img)
        
        for face in faces:
            face_emb = face.embedding.astype("float32")
            face_emb = l2_normalize(face_emb)
            
            # ê°¤ëŸ¬ë¦¬ì™€ ë§¤ì¹­
            best_person, best_sim = match_with_bank(face_emb, gallery)
            
            # í•´ë‹¹ ì¸ë¬¼ì´ê³  ì„ê³„ê°’ ì´ìƒì´ë©´ ìˆ˜ì§‘
            if best_person == person_id and best_sim >= match_threshold:
                # ì¤‘ë³µ ì²´í¬: ê¸°ì¡´ bankì™€ ë¹„êµ
                is_duplicate = False
                if bank.shape[0] > 0:
                    max_existing_sim = float(np.max(bank @ face_emb))
                    if max_existing_sim >= similarity_threshold:
                        is_duplicate = True
                
                # ìˆ˜ì§‘ëœ ì„ë² ë”©ê³¼ë„ ë¹„êµ
                if not is_duplicate and collected_embeddings:
                    collected_array = np.stack(collected_embeddings, axis=0)
                    max_collected_sim = float(np.max(collected_array @ face_emb))
                    if max_collected_sim >= similarity_threshold:
                        is_duplicate = True
                
                if not is_duplicate:
                    collected_embeddings.append(face_emb)
                    frame_info.append({
                        "frame": f_idx,
                        "similarity": best_sim,
                        "angle": estimate_face_angle(face)
                    })
                    print(f"  âœ… í”„ë ˆì„ {f_idx}: ìˆ˜ì§‘ (sim={best_sim:.3f}, ê°ë„={estimate_face_angle(face)})")
                    
                    if len(collected_embeddings) >= max_faces_per_person:
                        print(f"  â¹ ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜ ë„ë‹¬ ({max_faces_per_person}ê°œ)")
                        break
        
        if len(collected_embeddings) >= max_faces_per_person:
            break
    
    if not collected_embeddings:
        print(f"\nâš ï¸ {person_id}ì˜ ìƒˆë¡œìš´ ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return 0
    
    # Bankì— ì¶”ê°€
    new_embs_array = np.stack(collected_embeddings, axis=0)
    updated_bank = np.vstack([bank, new_embs_array])
    
    # Centroid ì¬ê³„ì‚°
    updated_centroid = updated_bank.mean(axis=0)
    updated_centroid = l2_normalize(updated_centroid)
    
    # ì €ì¥
    emb_dir.mkdir(parents=True, exist_ok=True)
    np.save(bank_path, updated_bank)
    
    centroid_path = emb_dir / f"{person_id}_centroid.npy"
    np.save(centroid_path, updated_centroid)
    
    legacy_path = emb_dir / f"{person_id}.npy"
    np.save(legacy_path, updated_centroid)
    
    print(f"\nâœ… Bank ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
    print(f"   ì¶”ê°€ëœ ì„ë² ë”©: {len(collected_embeddings)}ê°œ")
    print(f"   ì´ ì„ë² ë”© ìˆ˜: {updated_bank.shape[0]}ê°œ")
    print(f"   ìˆ˜ì§‘ëœ í”„ë ˆì„: {[info['frame'] for info in frame_info]}")
    
    return len(collected_embeddings)


def main():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    # ì„¤ì •
    video_path = Path("images") / "newjeans_dance.gif"
    person_id = "hani"  # ì˜†ì–¼êµ´ ì„ë² ë”©ì„ ì¶”ê°€í•  ì‚¬ëŒ
    emb_dir = Path("outputs") / "embeddings"
    
    print("=" * 60)
    print("ì˜ìƒì—ì„œ ë‹¤ì–‘í•œ ê°ë„ ì–¼êµ´ ì°¾ì•„ Bankì— ì¶”ê°€")
    print("=" * 60)
    
    # ê°¤ëŸ¬ë¦¬ ë¡œë“œ
    gallery = load_gallery(emb_dir, use_bank=True)
    if not gallery:
        raise RuntimeError(f"ê°¤ëŸ¬ë¦¬ ë¹„ì–´ ìˆìŒ: {emb_dir}")
    
    print("ğŸ‘¥ ê°¤ëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ:", list(gallery.keys()))
    
    # InsightFace ì´ˆê¸°í™”
    device_id = get_device_id()
    device_type = "GPU" if device_id >= 0 else "CPU"
    print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {device_type} (ctx_id={device_id})")
    
    app = FaceAnalysis(name="buffalo_l")
    actual_device_id = safe_prepare_insightface(app, device_id, det_size=(640, 640))
    
    # ë‹¤ì–‘í•œ ê°ë„ ì–¼êµ´ ì°¾ì•„ ì¶”ê°€
    added_count = find_diverse_faces_in_video(
        video_path=video_path,
        person_id=person_id,
        gallery=gallery,
        emb_dir=emb_dir,
        app=app,
        match_threshold=0.30,  # ì´ ê°’ ì´ìƒì´ë©´ í•´ë‹¹ ì¸ë¬¼ë¡œ ì¸ì‹
        similarity_threshold=0.90,  # ì´ ê°’ ì´ìƒì´ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
        max_faces_per_person=10  # ìµœëŒ€ 10ê°œê¹Œì§€ ì¶”ê°€
    )
    
    if added_count > 0:
        print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
        print(f"   python src/face_match_video_multi.py ì‹¤í–‰í•˜ì—¬ ì¸ì‹ ì„±ëŠ¥ í™•ì¸")


if __name__ == "__main__":
    main()



