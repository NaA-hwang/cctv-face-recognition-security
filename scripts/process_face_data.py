"""
ì–¼êµ´ ë°ì´í„° ì²˜ë¦¬ ë° ì„ë² ë”© ìƒì„± ìŠ¤í¬ë¦½íŠ¸
íŒ€ì›ë“¤ì˜ ì–¼êµ´ ì‚¬ì§„ì„ ì²˜ë¦¬í•˜ì—¬ AI ëª¨ë¸ìš© ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
RetinaFace + ArcFace ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

import os
import json
import cv2
import numpy as np
from pathlib import Path
import sqlite3
import pickle
from datetime import datetime
from PIL import Image
import argparse

# ===============================================================================
# **ì¤‘ìš”: InsightFace ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì˜ì¡´ì„± í•´ê²° í•„ìš”**
# ===============================================================================
# TODO: pip install insightface onnxruntime opencv-python ì‹¤í–‰ í•„ìš”
# TODO: ì‹¤ì œ íŒ€ì› ì–¼êµ´ ì‚¬ì§„ ë°ì´í„° ìˆ˜ì§‘ ë° ì •ë¦¬ í•„ìš”
# TODO: ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ ë° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ìë™í™”
# TODO: ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
# ===============================================================================

# InsightFace ëª¨ë¸ import
try:
    import insightface
    from insightface.app import FaceAnalysis
    from insightface.data import get_image as ins_get_image
    INSIGHTFACE_AVAILABLE = True
    print("âœ… InsightFace ëª¨ë¸ ë¡œë“œ ê°€ëŠ¥")
except ImportError as e:
    print(f"âš ï¸  InsightFace ì„¤ì¹˜ í•„ìš”: pip install insightface")
    print(f"Error: {e}")
    INSIGHTFACE_AVAILABLE = False

class FaceDataProcessor:
    """ì–¼êµ´ ë°ì´í„° ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, data_root="data"):
        self.data_root = Path(data_root)
        self.images_dir = self.data_root / "suspects" / "images"
        self.metadata_dir = self.data_root / "suspects" / "metadata"
        self.processed_dir = self.data_root / "suspects" / "processed"
        self.db_path = self.data_root / "embeddings" / "suspects.db"
        
        # ì²˜ë¦¬ëœ ë°ì´í„° ë””ë ‰í„°ë¦¬ ìƒì„±
        self.processed_dir.mkdir(parents=True, exist_ok=True)
        (self.data_root / "embeddings").mkdir(parents=True, exist_ok=True)
        
        # InsightFace ëª¨ë¸ ì´ˆê¸°í™”
        self.face_app = None
        self.init_face_models()
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        self.load_metadata()
        
    def init_face_models(self):
        """RetinaFace + ArcFace ëª¨ë¸ ì´ˆê¸°í™”"""
        if not INSIGHTFACE_AVAILABLE:
            print("âŒ InsightFaceë¥¼ ë¨¼ì € ì„¤ì¹˜í•´ì£¼ì„¸ìš”: pip install insightface")
            print("âŒ ì¶”ê°€ ì˜ì¡´ì„±: pip install onnxruntime")
            return False
            
        try:
            print("ğŸ¤– AI ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
            
            # FaceAnalysis ì•± ì´ˆê¸°í™” (RetinaFace + ArcFace í¬í•¨)
            self.face_app = FaceAnalysis(
                providers=['CPUExecutionProvider']  # GPU ì‚¬ìš©ì‹œ 'CUDAExecutionProvider' ì¶”ê°€
            )
            self.face_app.prepare(ctx_id=0, det_size=(640, 640))
            
            print("âœ… RetinaFace (ì–¼êµ´ê²€ì¶œ) + ArcFace (ì„ë² ë”©) ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            print(f"ğŸ“Š ê²€ì¶œ ëª¨ë¸: {self.face_app.det_model.__class__.__name__}")
            print(f"ğŸ§  ì¸ì‹ ëª¨ë¸: {self.face_app.rec_model.__class__.__name__}")
            return True
            
        except Exception as e:
            print(f"âŒ AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ í•´ê²°ë°©ë²•:")
            print("   1. pip install insightface onnxruntime")
            print("   2. ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ëŒ€ê¸° (ì²˜ìŒ ì‹¤í–‰ì‹œ)")
            self.face_app = None
            return False
        
    def load_metadata(self):
        """ë©”íƒ€ë°ì´í„° JSON íŒŒì¼ ë¡œë“œ"""
        metadata_file = self.metadata_dir / "suspect_profiles.json"
        
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                self.metadata = json.load(f)
            print(f"âœ… ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.metadata['suspects'])}ëª…")
        else:
            print(f"âŒ ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_file}")
            self.metadata = None
    
    def validate_images(self):
        """ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ë° í’ˆì§ˆ ê²€ì¦"""
        print("ğŸ” ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦ ì¤‘...")
        
        validation_results = {
            "total_suspects": 0,
            "valid_suspects": 0,
            "missing_images": [],
            "invalid_images": [],
            "quality_warnings": []
        }
        
        for suspect in self.metadata['suspects']:
            name_en = suspect['name_en']
            required_images = suspect['images']['required_angles']
            
            validation_results["total_suspects"] += 1
            suspect_valid = True
            
            print(f"\nğŸ“¸ {suspect['name']} ({name_en}) ê²€ì¦ ì¤‘...")
            
            for img_path in required_images:
                full_path = self.images_dir / img_path
                
                if not full_path.exists():
                    validation_results["missing_images"].append(str(full_path))
                    print(f"  âŒ ëˆ„ë½: {img_path}")
                    suspect_valid = False
                else:
                    # ì´ë¯¸ì§€ í’ˆì§ˆ ê²€ì‚¬
                    quality_check = self.check_image_quality(full_path)
                    if quality_check["valid"]:
                        print(f"  âœ… ìœ íš¨: {img_path} ({quality_check['resolution']})")
                    else:
                        validation_results["invalid_images"].append({
                            "path": str(full_path),
                            "issues": quality_check["issues"]
                        })
                        print(f"  âš ï¸ í’ˆì§ˆ ë¬¸ì œ: {img_path} - {quality_check['issues']}")
                        
                        if "resolution_too_low" in quality_check["issues"]:
                            suspect_valid = False
            
            if suspect_valid:
                validation_results["valid_suspects"] += 1
                print(f"  âœ… {suspect['name']}: ëª¨ë“  ì´ë¯¸ì§€ ê²€ì¦ ì™„ë£Œ")
            else:
                print(f"  âŒ {suspect['name']}: ì´ë¯¸ì§€ ë¬¸ì œ ìˆìŒ")
        
        return validation_results
    
    def check_image_quality(self, image_path):
        """ê°œë³„ ì´ë¯¸ì§€ í’ˆì§ˆ ê²€ì‚¬"""
        try:
            img = cv2.imread(str(image_path))
            if img is None:
                return {"valid": False, "issues": ["cannot_read"]}
            
            height, width = img.shape[:2]
            resolution = f"{width}x{height}"
            
            issues = []
            
            # í•´ìƒë„ ì²´í¬
            if width < 640 or height < 480:
                issues.append("resolution_too_low")
            
            # íŒŒì¼ í¬ê¸° ì²´í¬
            file_size = os.path.getsize(image_path)
            if file_size > 10 * 1024 * 1024:  # 10MB
                issues.append("file_too_large")
            elif file_size < 50 * 1024:  # 50KB
                issues.append("file_too_small")
            
            # ì´ë¯¸ì§€ ë°ê¸° ì²´í¬ (ë„ˆë¬´ ì–´ë‘ìš°ë©´ ì¸ì‹ ì–´ë ¤ì›€)
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            avg_brightness = np.mean(gray)
            if avg_brightness < 50:
                issues.append("too_dark")
            elif avg_brightness > 200:
                issues.append("too_bright")
            
            return {
                "valid": len(issues) == 0 or "resolution_too_low" not in issues,
                "resolution": resolution,
                "file_size": file_size,
                "brightness": avg_brightness,
                "issues": issues
            }
            
        except Exception as e:
            return {"valid": False, "issues": [f"error: {str(e)}"]}
    
    def process_images(self):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì–¼êµ´ ì •ë ¬, í¬ê¸° ì •ê·œí™”)"""
        print("ğŸ”„ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹œì‘...")
        
        # ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ì ì¸ ì „ì²˜ë¦¬ë§Œ ìˆ˜í–‰
        # ì‹¤ì œë¡œëŠ” InsightFaceì˜ face detectionê³¼ alignmentë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
        
        processed_count = 0
        
        for suspect in self.metadata['suspects']:
            name_en = suspect['name_en']
            processed_dir = self.processed_dir / "aligned_faces" / name_en
            processed_dir.mkdir(parents=True, exist_ok=True)
            
            print(f"ì²˜ë¦¬ ì¤‘: {suspect['name']} ({name_en})")
            
            for img_path in suspect['images']['required_angles']:
                source_path = self.images_dir / img_path
                
                if source_path.exists():
                    # ê¸°ë³¸ ì „ì²˜ë¦¬: í¬ê¸° ì¡°ì • ë° ì •ê·œí™”
                    processed_path = processed_dir / source_path.name
                    self.preprocess_image(source_path, processed_path)
                    processed_count += 1
        
        print(f"âœ… ì´ {processed_count}ê°œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ")
        return processed_count
    
    def preprocess_image(self, source_path, target_path):
        """ê°œë³„ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            img = cv2.imread(str(source_path))
            
            # í¬ê¸° ì •ê·œí™” (AI ëª¨ë¸ ì…ë ¥ìš©)
            target_size = (112, 112)  # InsightFace í‘œì¤€ í¬ê¸°
            resized = cv2.resize(img, target_size)
            
            # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” (ì¡°ëª… ì •ê·œí™”)
            lab = cv2.cvtColor(resized, cv2.COLOR_BGR2LAB)
            lab[:, :, 0] = cv2.equalizeHist(lab[:, :, 0])
            normalized = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            
            # ì €ì¥
            cv2.imwrite(str(target_path), normalized)
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨ {source_path}: {str(e)}")
    
    def create_sample_embeddings(self):
        """ìƒ˜í”Œ ì„ë² ë”© ìƒì„± (ì‹¤ì œ AI ëª¨ë¸ ì—†ì´ í…ŒìŠ¤íŠ¸ìš©)"""
        print("ğŸ”§ ìƒ˜í”Œ ì„ë² ë”© ìƒì„± ì¤‘...")
        
        embeddings_data = {}
        
        for suspect in self.metadata['suspects']:
            suspect_id = suspect['id']
            name = suspect['name']
            
            # ì‹¤ì œë¡œëŠ” InsightFace ArcFace ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•¨
            # ì—¬ê¸°ì„œëŠ” í…ŒìŠ¤íŠ¸ìš© ëœë¤ ì„ë² ë”© ìƒì„±
            np.random.seed(int(suspect_id) * 42)  # ì¬í˜„ ê°€ëŠ¥í•œ ëœë¤
            embedding = np.random.randn(512).astype(np.float32)
            embedding = embedding / np.linalg.norm(embedding)  # L2 ì •ê·œí™”
            
            embeddings_data[suspect_id] = {
                "name": name,
                "embedding": embedding,
                "created_date": datetime.now().isoformat()
            }
            
            print(f"  âœ… {name}: ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: {embedding.shape})")
        
        # ì„ë² ë”© ë°ì´í„° ì €ì¥
        embeddings_file = self.processed_dir / "embeddings.pkl"
        with open(embeddings_file, 'wb') as f:
            pickle.dump(embeddings_data, f)
        
        print(f"âœ… ì„ë² ë”© ë°ì´í„° ì €ì¥: {embeddings_file}")
        return embeddings_data
    
    def update_database(self, embeddings_data):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸"""
        print("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘...")
        
        # ì—¬ê¸°ì„œëŠ” backend/models/embedding_db.pyì˜ EmbeddingDatabase í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
        # í˜„ì¬ëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œë§Œ ì œê³µ
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„± (ê°„ë‹¨ ë²„ì „)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS test_embeddings (
                    id TEXT PRIMARY KEY,
                    name TEXT,
                    embedding BLOB,
                    created_date TEXT
                )
            """)
            
            # ë°ì´í„° ì‚½ì…
            for suspect_id, data in embeddings_data.items():
                embedding_blob = pickle.dumps(data['embedding'])
                
                cursor.execute("""
                    INSERT OR REPLACE INTO test_embeddings 
                    (id, name, embedding, created_date)
                    VALUES (?, ?, ?, ?)
                """, (suspect_id, data['name'], embedding_blob, data['created_date']))
            
            conn.commit()
            conn.close()
            
            print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {self.db_path}")
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
    
    def generate_report(self, validation_results, processed_count, embeddings_count):
        """ì²˜ë¦¬ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = f"""
# ì–¼êµ´ ë°ì´í„° ì²˜ë¦¬ ë¦¬í¬íŠ¸
ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
- ì´ ìš©ì˜ì ìˆ˜: {validation_results['total_suspects']}ëª…
- ìœ íš¨í•œ ìš©ì˜ì: {validation_results['valid_suspects']}ëª…  
- ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {processed_count}ê°œ
- ìƒì„±ëœ ì„ë² ë”©: {embeddings_count}ê°œ

## âœ… ì„±ê³µí•œ ìš©ì˜ìë“¤
"""
        
        for suspect in self.metadata['suspects']:
            if suspect['name_en'] not in [str(p).split('/')[-2] for p in validation_results['missing_images']]:
                report += f"- {suspect['name']} ({suspect['name_en']}): {suspect['images']['total_count']}ì¥\n"
        
        if validation_results['missing_images']:
            report += "\n## âŒ ëˆ„ë½ëœ ì´ë¯¸ì§€ë“¤\n"
            for missing in validation_results['missing_images']:
                report += f"- {missing}\n"
        
        if validation_results['invalid_images']:
            report += "\n## âš ï¸ í’ˆì§ˆ ë¬¸ì œ ì´ë¯¸ì§€ë“¤\n"
            for invalid in validation_results['invalid_images']:
                report += f"- {invalid['path']}: {invalid['issues']}\n"
        
        report += f"""
## ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤
- ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€: `{self.processed_dir}/aligned_faces/`
- ì„ë² ë”© ë°ì´í„°: `{self.processed_dir}/embeddings.pkl`
- ë°ì´í„°ë² ì´ìŠ¤: `{self.db_path}`

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„
1. ëˆ„ë½ëœ ì´ë¯¸ì§€ë“¤ì„ ì´¬ì˜í•˜ì—¬ ì¶”ê°€
2. í’ˆì§ˆ ë¬¸ì œê°€ ìˆëŠ” ì´ë¯¸ì§€ë“¤ì„ ì¬ì´¬ì˜  
3. AI ëª¨ë¸ ì„œë²„ ì‹¤í–‰í•˜ì—¬ ì‹¤ì œ ì„ë² ë”© ìƒì„±
4. CCTV ì‹œìŠ¤í…œì—ì„œ í…ŒìŠ¤íŠ¸
"""
        
        # ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥
        report_file = self.processed_dir / "processing_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\nğŸ“‹ ì²˜ë¦¬ ë¦¬í¬íŠ¸ ì €ì¥: {report_file}")
        print(report)
        
        return report


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="íŒ€ì› ì–¼êµ´ ë°ì´í„° ì²˜ë¦¬")
    parser.add_argument("--data-root", default="data", help="ë°ì´í„° ë£¨íŠ¸ ë””ë ‰í„°ë¦¬")
    parser.add_argument("--validate-only", action="store_true", help="ê²€ì¦ë§Œ ìˆ˜í–‰")
    parser.add_argument("--skip-processing", action="store_true", help="ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê±´ë„ˆë›°ê¸°")
    
    args = parser.parse_args()
    
    print("ğŸš€ íŒ€ì› ì–¼êµ´ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
    print("=" * 50)
    
    # ë°ì´í„° ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
    processor = FaceDataProcessor(args.data_root)
    
    if processor.metadata is None:
        print("âŒ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # 1. ì´ë¯¸ì§€ ê²€ì¦
    validation_results = processor.validate_images()
    
    if args.validate_only:
        print("\nâœ… ê²€ì¦ ì™„ë£Œ. ì²˜ë¦¬ ê³¼ì •ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    processed_count = 0
    embeddings_count = 0
    
    # 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    if not args.skip_processing:
        processed_count = processor.process_images()
    
    # 3. ì„ë² ë”© ìƒì„± (ìƒ˜í”Œ)
    embeddings_data = processor.create_sample_embeddings()
    embeddings_count = len(embeddings_data)
    
    # 4. ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
    processor.update_database(embeddings_data)
    
    # 5. ë¦¬í¬íŠ¸ ìƒì„±
    processor.generate_report(validation_results, processed_count, embeddings_count)
    
    print("\nğŸ‰ ëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("\në‹¤ìŒìœ¼ë¡œ í•  ì¼:")
    print("1. ëˆ„ë½ëœ ì´ë¯¸ì§€ë“¤ì„ ì´¬ì˜í•˜ì—¬ í•´ë‹¹ í´ë”ì— ì €ì¥")
    print("2. backend/app.pyë¥¼ ì‹¤í–‰í•˜ì—¬ AI ì„œë²„ ì‹œì‘")
    print("3. HTML í˜ì´ì§€ì—ì„œ ì‹¤ì œ ì–¼êµ´ ì¸ì‹ í…ŒìŠ¤íŠ¸")


if __name__ == "__main__":
    main()