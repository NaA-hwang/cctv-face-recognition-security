from __future__ import annotations

# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬: ì´ë¯¸ì§€ ì¸ì½”ë”©, íŒŒì¼ I/O, ê²½ë¡œ ì²˜ë¦¬, ì„ì‹œ íŒŒì¼ ìƒì„± ë“±ì— ì‚¬ìš©
import base64
import io
import os
from pathlib import Path
from tempfile import NamedTemporaryFile
from typing import Dict, Optional

# InsightFace GPU ì„¤ì •
# ONNX Runtimeì´ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •
try:
    import onnxruntime as ort
    available_providers = ort.get_available_providers()
    if 'CUDAExecutionProvider' in available_providers:
        print(f"âœ“ GPU ì‚¬ìš© ê°€ëŠ¥ (ONNX Runtime)")
        GPU_AVAILABLE = True
        DEVICE_ID = 0  # GPU ì‚¬ìš©
    else:
        print("âš  GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        GPU_AVAILABLE = False
        DEVICE_ID = -1  # CPU ì‚¬ìš©
except ImportError:
    print("âš  ONNX Runtimeì„ ì„í¬íŠ¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    GPU_AVAILABLE = False
    DEVICE_ID = -1
except Exception as e:
    print(f"âš  GPU í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    GPU_AVAILABLE = False
    DEVICE_ID = -1

# FastAPI ê´€ë ¨: ì›¹ í”„ë ˆì„ì›Œí¬, íŒŒì¼ ì—…ë¡œë“œ, HTML ì‘ë‹µ, í…œí”Œë¦¿ ì—”ì§„
from fastapi import FastAPI, File, Request, UploadFile
from fastapi.responses import HTMLResponse, StreamingResponse
from fastapi.templating import Jinja2Templates
# PIL: ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
from PIL import Image, ImageDraw, ImageFont
# InsightFace: ì–¼êµ´ ê°ì§€ ë° ì¸ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
import insightface
from insightface.app import FaceAnalysis
# OpenCV: ì˜ìƒ ì²˜ë¦¬ ë° í”„ë ˆì„ ì¶”ì¶œ
import cv2
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
# HTML í…œí”Œë¦¿ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
TEMPLATES_DIR = BASE_DIR / "templates"
# ì˜ˆì‹œ íŒŒì¼ ê²½ë¡œ ì„¤ì •
EXAMPLE_IMAGE_PATH = BASE_DIR.parent / "data" / "newjeans.jpg"
EXAMPLE_VIDEO_PATH = BASE_DIR.parent / "data" / "video.mp4"

# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = FastAPI(
    title="InsightFace ì–¼êµ´ ì¸ì‹ ë°ëª¨",
    description="InsightFaceë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì–¼êµ´ì„ ì´ë¯¸ì§€/ì˜ìƒì—ì„œ ì°¾ëŠ” ì›¹ ë°ëª¨.",
)

# InsightFace FaceAnalysis ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì´ˆê¸°í™”)
face_app: Optional[FaceAnalysis] = None


@app.on_event("startup")
async def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ InsightFace ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global face_app
    
    print("\n" + "=" * 50)
    print("ğŸš€ FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘")
    print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {'GPU' if GPU_AVAILABLE else 'CPU'} (ctx_id={DEVICE_ID})")
    
    try:
        # InsightFace FaceAnalysis ì´ˆê¸°í™” (buffalo_l ëª¨ë¸ ì‚¬ìš©)
        face_app = FaceAnalysis(name="buffalo_l")
        face_app.prepare(ctx_id=DEVICE_ID, det_size=(640, 640))
        print("âœ… InsightFace ëª¨ë¸ 'buffalo_l' ë¡œë“œ ì™„ë£Œ")
        print("=" * 50 + "\n")
    except Exception as e:
        print(f"âŒ InsightFace ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("=" * 50 + "\n")
        raise


# Jinja2 í…œí”Œë¦¿ ì—”ì§„ ì´ˆê¸°í™” (HTML í…œí”Œë¦¿ ë Œë”ë§ìš©)
templates = Jinja2Templates(directory=str(TEMPLATES_DIR))


def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """
    ë‘ ì„ë² ë”© ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        a: ì²« ë²ˆì§¸ ì„ë² ë”© ë²¡í„°
        b: ë‘ ë²ˆì§¸ ì„ë² ë”© ë²¡í„°
    
    Returns:
        ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (0~1 ì‚¬ì´ ê°’, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)
    """
    # ì •ê·œí™”
    a_norm = a / np.linalg.norm(a)
    b_norm = b / np.linalg.norm(b)
    return float(np.dot(a_norm, b_norm))


def _encode_image_with_face_matches(
    image_bytes: bytes, faces: list, target_embedding: np.ndarray, threshold: float = 0.3
) -> str:
    """
    ê°ì§€ëœ ì–¼êµ´ì— ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë ¤ì„œ base64 ì¸ì½”ë”©ëœ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜.
    ì°¾ì€ ì–¼êµ´(ë§¤ì¹­ëœ ì–¼êµ´)ì€ ë¹¨ê°„ìƒ‰, ì¼ë°˜ ì–¼êµ´ì€ ì´ˆë¡ìƒ‰ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
    
    Args:
        image_bytes: ì›ë³¸ ì´ë¯¸ì§€ì˜ ë°”ì´íŠ¸ ë°ì´í„°
        faces: InsightFaceê°€ ê°ì§€í•œ ì–¼êµ´ ë¦¬ìŠ¤íŠ¸
        target_embedding: ì°¾ì„ ì–¼êµ´ì˜ ì„ë² ë”© ë²¡í„°
        threshold: ë§¤ì¹­ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.3)
    
    Returns:
        base64ë¡œ ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë¬¸ìì—´ (HTMLì—ì„œ ì§ì ‘ í‘œì‹œ ê°€ëŠ¥)
    """
    # ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ PIL Image ê°ì²´ë¡œ ë³€í™˜ (RGB í˜•ì‹ìœ¼ë¡œ í†µì¼)
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    # ì´ë¯¸ì§€ì— ê·¸ë¦¼ì„ ê·¸ë¦¬ê¸° ìœ„í•œ Draw ê°ì²´ ìƒì„±
    draw = ImageDraw.Draw(image)

    matched_count = 0
    
    # ê°ì§€ëœ ê° ì–¼êµ´ì— ëŒ€í•´ ë°”ìš´ë”© ë°•ìŠ¤ì™€ ë§¤ì¹­ ì •ë³´ í‘œì‹œ
    for face in faces:
        # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì¶”ì¶œ (x1, y1, x2, y2)
        bbox = face.bbox.astype(int)
        x1, y1, x2, y2 = bbox
        
        # ì„ë² ë”© ë¹„êµ
        similarity = cosine_similarity(target_embedding, face.embedding)
        is_matched = similarity >= threshold
        
        if is_matched:
            matched_count += 1
            # ì°¾ì€ ì–¼êµ´: ë¹¨ê°„ìƒ‰ ë°”ìš´ë”© ë°•ìŠ¤
            color = "#FF0000"
            label = f"Matched! {similarity:.2f}"
        else:
            # ì¼ë°˜ ì–¼êµ´: ì´ˆë¡ìƒ‰ ë°”ìš´ë”© ë°•ìŠ¤
            color = "#00FF00"
            label = f"{similarity:.2f}"
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë‘ê»˜ 3í”½ì…€)
        draw.rectangle([(x1, y1), (x2, y2)], outline=color, width=3)
        
        # í…ìŠ¤íŠ¸ ë°°ê²½ì„ ìœ„í•œ ì¢Œí‘œ ê³„ì‚°
        label_x = x1 + 4
        label_y = y1 - 25 if y1 > 25 else y1 + 4
        
        # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸° (ê°€ë…ì„± í–¥ìƒ)
        try:
            # í…ìŠ¤íŠ¸ í¬ê¸° ì¶”ì •
            bbox_text = draw.textbbox((label_x, label_y), label)
            text_width = bbox_text[2] - bbox_text[0]
            text_height = bbox_text[3] - bbox_text[1]
            draw.rectangle(
                [(label_x - 2, label_y - text_height - 2), (label_x + text_width + 2, label_y + 2)],
                fill=color,
            )
            # í…ìŠ¤íŠ¸ë¥¼ í°ìƒ‰ìœ¼ë¡œ í‘œì‹œ
            draw.text((label_x, label_y - text_height), label, fill="#FFFFFF")
        except:
            # í°íŠ¸ ë¬¸ì œ ì‹œ ê°„ë‹¨í•˜ê²Œ í‘œì‹œ
            draw.text((label_x, label_y), label, fill=color)

    # ì´ë¯¸ì§€ë¥¼ JPEG í˜•ì‹ìœ¼ë¡œ ë©”ëª¨ë¦¬ ë²„í¼ì— ì €ì¥
    buffer = io.BytesIO()
    image.save(buffer, format="JPEG")
    # ë²„í¼ì˜ ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ base64 ë¬¸ìì—´ë¡œ ì¸ì½”ë”© (HTML img íƒœê·¸ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
    encoded = base64.b64encode(buffer.getvalue()).decode("utf-8")
    return encoded, matched_count


@app.get("/", response_class=HTMLResponse)
async def index(request: Request) -> HTMLResponse:
    """
    ë©”ì¸ í˜ì´ì§€ ì—”ë“œí¬ì¸íŠ¸.
    ì‚¬ìš©ìê°€ ì²˜ìŒ ì ‘ì†í•˜ê±°ë‚˜ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤.
    ë¹ˆ ìƒíƒœì˜ ì—…ë¡œë“œ í¼ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
    """
    # index.html í…œí”Œë¦¿ì„ ë Œë”ë§í•˜ì—¬ ë°˜í™˜
    # ì´ˆê¸° ìƒíƒœì´ë¯€ë¡œ ê²°ê³¼ ì´ë¯¸ì§€ì™€ ì–¼êµ´ ê°œìˆ˜ëŠ” Noneìœ¼ë¡œ ì„¤ì •
    return templates.TemplateResponse(
        "index.html",
        {
            "request": request,
            "result_image": None,
            "message": "ì°¾ì„ ì–¼êµ´ ì´ë¯¸ì§€ì™€ ëŒ€ìƒ ì´ë¯¸ì§€/ì˜ìƒì„ ì—…ë¡œë“œí•´ì„œ íŠ¹ì • ì–¼êµ´ì„ ì°¾ì•„ë³´ì„¸ìš”.",
            "faces_found": None,
            "matched_faces": None,
            "result_video": None,
            "total_frames": None,
            "frames_with_faces": None,
            "frames_with_matches": None,
            "processing_time": None,
        },
    )


@app.post("/detect", response_class=HTMLResponse)
async def detect_faces(
    request: Request,
    target_face: UploadFile = File(..., description="ì°¾ì„ ì–¼êµ´ ì´ë¯¸ì§€"),
    search_image: UploadFile = File(..., description="ì—¬ëŸ¬ ì–¼êµ´ì´ í¬í•¨ëœ ì´ë¯¸ì§€"),
) -> HTMLResponse:
    """
    íŠ¹ì • ì–¼êµ´ ê°ì§€ ì—”ë“œí¬ì¸íŠ¸.
    ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì°¾ì„ ì–¼êµ´ ì´ë¯¸ì§€ì™€ ëŒ€ìƒ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì„œ InsightFaceë¡œ íŠ¹ì • ì–¼êµ´ì„ ì°¾ê³ ,
    ê²°ê³¼ ì´ë¯¸ì§€ì™€ í•¨ê»˜ HTML í˜ì´ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    global face_app
    
    # ê²°ê³¼ ë©”ì‹œì§€, ì¸ì½”ë”©ëœ ì´ë¯¸ì§€, ê°ì§€ëœ ì–¼êµ´ ê°œìˆ˜ë¥¼ ì €ì¥í•  ë³€ìˆ˜ ì´ˆê¸°í™”
    message: Optional[str] = None
    result_image: Optional[str] = None
    faces_found: Optional[int] = None
    matched_faces: Optional[int] = None

    if face_app is None:
        message = "InsightFace ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ë¥¼ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”."
    else:
        target_path = None
        search_path = None
        try:
            # ì°¾ì„ ì–¼êµ´ ì´ë¯¸ì§€ ì €ì¥
            target_contents = await target_face.read()
            if not target_contents:
                message = "ì°¾ì„ ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            else:
                with NamedTemporaryFile(delete=False, suffix=Path(target_face.filename).suffix) as tmp:
                    tmp.write(target_contents)
                    target_path = tmp.name

                # ëŒ€ìƒ ì´ë¯¸ì§€ ì €ì¥
                search_contents = await search_image.read()
                if not search_contents:
                    message = "ëŒ€ìƒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                else:
                    with NamedTemporaryFile(delete=False, suffix=Path(search_image.filename).suffix) as tmp:
                        tmp.write(search_contents)
                        search_path = tmp.name

                    # ì°¾ì„ ì–¼êµ´ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ
                    target_img = cv2.imread(target_path)
                    target_img_rgb = cv2.cvtColor(target_img, cv2.COLOR_BGR2RGB)
                    target_faces = face_app.get(target_img_rgb)
                    
                    if len(target_faces) == 0:
                        message = "ì°¾ì„ ì–¼êµ´ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    else:
                        # ì²« ë²ˆì§¸ ì–¼êµ´ì˜ ì„ë² ë”© ì‚¬ìš©
                        target_embedding = target_faces[0].embedding
                        
                        # ëŒ€ìƒ ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  ì–¼êµ´ ê°ì§€
                        search_img = cv2.imread(search_path)
                        search_img_rgb = cv2.cvtColor(search_img, cv2.COLOR_BGR2RGB)
                        search_faces = face_app.get(search_img_rgb)
                        
                        if len(search_faces) == 0:
                            message = "ëŒ€ìƒ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        else:
                            faces_found = len(search_faces)
                            # ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
                            result_image, matched_faces = _encode_image_with_face_matches(
                                search_contents, search_faces, target_embedding, threshold=0.3
                            )
                            message = f"ì´ {faces_found}ê°œì˜ ì–¼êµ´ ì¤‘ {matched_faces}ê°œì˜ ì–¼êµ´ì´ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆë‹¤."
                            
        except Exception as exc:
            message = f"ì²˜ë¦¬ ë„ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}"
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if target_path and os.path.exists(target_path):
                os.remove(target_path)
            if search_path and os.path.exists(search_path):
                os.remove(search_path)

    # ê²°ê³¼ë¥¼ í¬í•¨í•œ HTML í˜ì´ì§€ ë°˜í™˜
    return templates.TemplateResponse(
        "index.html",
        {
            "request": request,
            "result_image": result_image,
            "message": message,
            "faces_found": faces_found,
            "matched_faces": matched_faces,
            "result_video": None,
        },
    )




def _draw_boxes_on_frame(
    frame: np.ndarray, faces: list, target_embedding: np.ndarray, threshold: float = 0.3
) -> tuple[np.ndarray, int]:
    """
    í”„ë ˆì„ì— ê°ì§€ëœ ì–¼êµ´ì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜.
    ì°¾ì€ ì–¼êµ´(ë§¤ì¹­ëœ ì–¼êµ´)ì€ ë¹¨ê°„ìƒ‰, ì¼ë°˜ ì–¼êµ´ì€ ì´ˆë¡ìƒ‰ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
    
    Args:
        frame: OpenCVë¡œ ì½ì€ í”„ë ˆì„ (numpy ë°°ì—´, BGR í˜•ì‹)
        faces: InsightFaceê°€ ê°ì§€í•œ ì–¼êµ´ ë¦¬ìŠ¤íŠ¸
        target_embedding: ì°¾ì„ ì–¼êµ´ì˜ ì„ë² ë”© ë²¡í„°
        threshold: ë§¤ì¹­ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.3)
    
    Returns:
        (ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ í”„ë ˆì„, ë§¤ì¹­ëœ ì–¼êµ´ ìˆ˜) íŠœí”Œ
    """
    # í”„ë ˆì„ ë³µì‚¬ (ì›ë³¸ ë³´ì¡´)
    result_frame = frame.copy()
    matched_count = 0
    
    # ê°ì§€ëœ ê° ì–¼êµ´ì— ëŒ€í•´ ë°”ìš´ë”© ë°•ìŠ¤ì™€ ë§¤ì¹­ ì •ë³´ í‘œì‹œ
    for face in faces:
        # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì¶”ì¶œ (x1, y1, x2, y2)
        bbox = face.bbox.astype(int)
        x1, y1, x2, y2 = bbox
        
        # ì„ë² ë”© ë¹„êµ
        similarity = cosine_similarity(target_embedding, face.embedding)
        is_matched = similarity >= threshold
        
        if is_matched:
            matched_count += 1
            # ì°¾ì€ ì–¼êµ´: ë¹¨ê°„ìƒ‰ ë°”ìš´ë”© ë°•ìŠ¤ (BGR í˜•ì‹: (0, 0, 255))
            color = (0, 0, 255)
            label = f"ë§¤ì¹­! {similarity:.2f}"
        else:
            # ì¼ë°˜ ì–¼êµ´: ì´ˆë¡ìƒ‰ ë°”ìš´ë”© ë°•ìŠ¤ (BGR í˜•ì‹: (0, 255, 0))
            color = (0, 255, 0)
            label = f"{similarity:.2f}"
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë‘ê»˜ 3í”½ì…€)
        cv2.rectangle(result_frame, (x1, y1), (x2, y2), color, 3)
        
        # í…ìŠ¤íŠ¸ ë°°ê²½ì„ ìœ„í•œ ì¢Œí‘œ ê³„ì‚°
        label_x = x1 + 4
        label_y = y1 - 20 if y1 > 20 else y1 + 20
        
        # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸° (ê°€ë…ì„± í–¥ìƒ)
        (text_width, text_height), _ = cv2.getTextSize(
            label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
        )
        cv2.rectangle(
            result_frame,
            (label_x - 2, label_y - text_height - 2),
            (label_x + text_width + 2, label_y + 2),
            color,
            -1,
        )
        # í…ìŠ¤íŠ¸ë¥¼ í°ìƒ‰ìœ¼ë¡œ í‘œì‹œ
        cv2.putText(
            result_frame,
            label,
            (label_x, label_y),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (255, 255, 255),
            2,
        )
    
    return result_frame, matched_count


def _process_video(
    video_path: str, output_path: str, target_embedding: np.ndarray, threshold: float = 0.3
) -> tuple[int, int, int, float]:
    """
    ì˜ìƒì˜ ê° í”„ë ˆì„ì— ëŒ€í•´ íŠ¹ì • ì–¼êµ´ì„ ì°¾ê³  ê²°ê³¼ ì˜ìƒì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    
    Args:
        video_path: ì…ë ¥ ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        output_path: ì¶œë ¥ ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        target_embedding: ì°¾ì„ ì–¼êµ´ì˜ ì„ë² ë”© ë²¡í„°
        threshold: ë§¤ì¹­ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.3)
    
    Returns:
        (ì´ í”„ë ˆì„ ìˆ˜, ê°ì§€ëœ ì–¼êµ´ì´ ìˆëŠ” í”„ë ˆì„ ìˆ˜, ë§¤ì¹­ëœ ì–¼êµ´ì´ ìˆëŠ” í”„ë ˆì„ ìˆ˜, ì²˜ë¦¬ ì‹œê°„(ì´ˆ)) íŠœí”Œ
    """
    global face_app
    
    # ì˜ìƒ íŒŒì¼ ì—´ê¸°
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError("ì˜ìƒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # ì¶œë ¥ ì˜ìƒ ì‘ì„±ì ì´ˆê¸°í™”
    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    frames_with_faces = 0
    frames_with_matches = 0
    frame_count = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # í”„ë ˆì„ì„ RGBë¡œ ë³€í™˜
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # InsightFaceë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ ê°ì§€ ìˆ˜í–‰
            faces = face_app.get(frame_rgb)
            
            if len(faces) > 0:
                frames_with_faces += 1
                # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                frame, matched_count = _draw_boxes_on_frame(frame, faces, target_embedding, threshold)
                if matched_count > 0:
                    frames_with_matches += 1
            
            # ì²˜ë¦¬ëœ í”„ë ˆì„ì„ ì¶œë ¥ ì˜ìƒì— ì‘ì„±
            out.write(frame)
    
    finally:
        # ë¦¬ì†ŒìŠ¤ í•´ì œ
        cap.release()
        out.release()
    
    return total_frames, frames_with_faces, frames_with_matches, frame_count / fps if fps > 0 else 0


@app.post("/detect_video", response_class=HTMLResponse)
async def detect_faces_in_video(
    request: Request,
    target_face: UploadFile = File(..., description="ì°¾ì„ ì–¼êµ´ ì´ë¯¸ì§€"),
    search_video: UploadFile = File(..., description="ì—¬ëŸ¬ ì–¼êµ´ì´ í¬í•¨ëœ ì˜ìƒ"),
) -> HTMLResponse:
    """
    ì˜ìƒì—ì„œ íŠ¹ì • ì–¼êµ´ ê°ì§€ ì—”ë“œí¬ì¸íŠ¸.
    ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì°¾ì„ ì–¼êµ´ ì´ë¯¸ì§€ì™€ ëŒ€ìƒ ì˜ìƒì„ ë°›ì•„ì„œ ê° í”„ë ˆì„ì— ëŒ€í•´ InsightFaceë¡œ íŠ¹ì • ì–¼êµ´ì„ ì°¾ê³ ,
    ê²°ê³¼ ì˜ìƒì„ ìƒì„±í•˜ì—¬ ë‹¤ìš´ë¡œë“œ ë§í¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    global face_app
    
    message: Optional[str] = None
    result_video: Optional[str] = None
    total_frames: Optional[int] = None
    frames_with_faces: Optional[int] = None
    frames_with_matches: Optional[int] = None
    processing_time: Optional[float] = None

    if face_app is None:
        message = "InsightFace ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ë¥¼ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”."
    else:
        target_path = None
        input_path = None
        output_path = None
        try:
            # ì°¾ì„ ì–¼êµ´ ì´ë¯¸ì§€ ì €ì¥
            target_contents = await target_face.read()
            if not target_contents:
                message = "ì°¾ì„ ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            else:
                with NamedTemporaryFile(delete=False, suffix=Path(target_face.filename).suffix) as tmp:
                    tmp.write(target_contents)
                    target_path = tmp.name

                # ì°¾ì„ ì–¼êµ´ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ
                target_img = cv2.imread(target_path)
                target_img_rgb = cv2.cvtColor(target_img, cv2.COLOR_BGR2RGB)
                target_faces = face_app.get(target_img_rgb)
                
                if len(target_faces) == 0:
                    message = "ì°¾ì„ ì–¼êµ´ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                else:
                    # ì²« ë²ˆì§¸ ì–¼êµ´ì˜ ì„ë² ë”© ì‚¬ìš©
                    target_embedding = target_faces[0].embedding
                    
                    # ëŒ€ìƒ ì˜ìƒ ì €ì¥
                    video_contents = await search_video.read()
                    if not video_contents:
                        message = "ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    else:
                        input_suffix = Path(search_video.filename).suffix or ".mp4"
                        with NamedTemporaryFile(delete=False, suffix=input_suffix) as tmp:
                            tmp.write(video_contents)
                            input_path = tmp.name
                        
                        # ì¶œë ¥ ì˜ìƒ ì„ì‹œ íŒŒì¼ ìƒì„±
                        with NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
                            output_path = tmp.name
                        
                        # ì˜ìƒ ì²˜ë¦¬ ìˆ˜í–‰
                        total_frames, frames_with_faces, frames_with_matches, processing_time = _process_video(
                            input_path, output_path, target_embedding, threshold=0.3
                        )
                        
                        # ê²°ê³¼ ì˜ìƒì„ base64ë¡œ ì¸ì½”ë”©
                        with open(output_path, "rb") as f:
                            video_bytes = f.read()
                            result_video = base64.b64encode(video_bytes).decode("utf-8")
                        
                        message = (
                            f"ì²˜ë¦¬ ì™„ë£Œ! ì´ {total_frames}ê°œ í”„ë ˆì„ ì¤‘ "
                            f"{frames_with_faces}ê°œ í”„ë ˆì„ì—ì„œ ì–¼êµ´ì„ ê°ì§€í–ˆê³ , "
                            f"{frames_with_matches}ê°œ í”„ë ˆì„ì—ì„œ ë§¤ì¹­ëœ ì–¼êµ´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. "
                            f"(ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ)"
                        )
                        
        except Exception as exc:
            message = f"ì˜ìƒ ì²˜ë¦¬ ë„ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}"
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if target_path and os.path.exists(target_path):
                os.remove(target_path)
            if input_path and os.path.exists(input_path):
                os.remove(input_path)
            if output_path and os.path.exists(output_path):
                os.remove(output_path)
    
    # ê²°ê³¼ë¥¼ í¬í•¨í•œ HTML í˜ì´ì§€ ë°˜í™˜
    return templates.TemplateResponse(
        "index.html",
        {
            "request": request,
            "result_image": None,
            "message": message,
            "faces_found": None,
            "matched_faces": None,
            "result_video": result_video,
            "total_frames": total_frames,
            "frames_with_faces": frames_with_faces,
            "frames_with_matches": frames_with_matches,
            "processing_time": processing_time,
        },
    )


