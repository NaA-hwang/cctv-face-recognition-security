from __future__ import annotations

# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬: ì´ë¯¸ì§€ ì¸ì½”ë”©, íŒŒì¼ I/O, ê²½ë¡œ ì²˜ë¦¬, ì„ì‹œ íŒŒì¼ ìƒì„± ë“±ì— ì‚¬ìš©
import base64
import io
import os
from pathlib import Path
from tempfile import NamedTemporaryFile
from typing import Dict, Optional

# TensorFlow GPU ì„¤ì • (RetinaFaceê°€ ì‚¬ìš©í•˜ë¯€ë¡œ ë¨¼ì € ì„¤ì •)
# RetinaFaceê°€ TensorFlowë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ TensorFlow GPU ì„¤ì •ì„ ë¨¼ì € ìˆ˜í–‰
os.environ["TF_USE_LEGACY_KERAS"] = "1"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"  # TensorFlow ë¡œê·¸ ë ˆë²¨ ì„¤ì • (ì—ëŸ¬ë§Œ í‘œì‹œ)
os.environ["TF_FORCE_GPU_ALLOW_GROWTH"] = "true"  # GPU ë©”ëª¨ë¦¬ ë™ì  ì¦ê°€ í—ˆìš©

# TensorFlowë¥¼ ì„í¬íŠ¸í•˜ì—¬ GPU í™•ì¸ ë° ì„¤ì •
try:
    import tensorflow as tf
    
    # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    gpus = tf.config.list_physical_devices("GPU")
    if gpus:
        # GPUê°€ ìˆëŠ” ê²½ìš° ë©”ëª¨ë¦¬ ì¦ê°€ í—ˆìš© ì„¤ì •
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"âœ“ GPU ê°ì§€ë¨: {len(gpus)}ê°œì˜ GPU ì‚¬ìš© ê°€ëŠ¥")
            for i, gpu in enumerate(gpus):
                print(f"  - GPU {i}: {gpu.name}")
        except RuntimeError as e:
            # GPU ë©”ëª¨ë¦¬ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì´ë¯¸ ì„¤ì •ëœ ê²½ìš° ë“±)
            print(f"GPU ë©”ëª¨ë¦¬ ì„¤ì • ê²½ê³ : {e}")
        GPU_AVAILABLE = True
    else:
        print("âš  GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        GPU_AVAILABLE = False
except ImportError:
    print("âš  TensorFlowë¥¼ ì„í¬íŠ¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GPU í™•ì¸ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    GPU_AVAILABLE = False
except Exception as e:
    print(f"âš  GPU í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    GPU_AVAILABLE = False

# FastAPI ê´€ë ¨: ì›¹ í”„ë ˆì„ì›Œí¬, íŒŒì¼ ì—…ë¡œë“œ, HTML ì‘ë‹µ, í…œí”Œë¦¿ ì—”ì§„
from fastapi import FastAPI, File, Request, UploadFile
from fastapi.responses import HTMLResponse, StreamingResponse
from fastapi.templating import Jinja2Templates
# PIL: ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
from PIL import Image, ImageDraw
# RetinaFace: ì–¼êµ´ ê°ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬
from retinaface import RetinaFace
# OpenCV: ì˜ìƒ ì²˜ë¦¬ ë° í”„ë ˆì„ ì¶”ì¶œ
import cv2
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
# HTML í…œí”Œë¦¿ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
TEMPLATES_DIR = BASE_DIR / "templates"
# ì˜ˆì‹œ íŒŒì¼ ê²½ë¡œ ì„¤ì •
EXAMPLE_IMAGE_PATH = BASE_DIR.parent / "data" / "newjeans.jpg"
EXAMPLE_VIDEO_PATH = BASE_DIR.parent / "data" / "video.mp4"

# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = FastAPI(
    title="RetinaFace Demo",
    description="Web demo that detects faces on uploaded images with RetinaFace.",
)


@app.on_event("startup")
async def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ GPU ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    if GPU_AVAILABLE:
        try:
            import tensorflow as tf
            gpus = tf.config.list_physical_devices("GPU")
            print("\n" + "=" * 50)
            print("ğŸš€ FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘")
            print(f"âœ“ GPU ëª¨ë“œ: {len(gpus)}ê°œì˜ GPU ì‚¬ìš© ì¤‘")
            for i, gpu in enumerate(gpus):
                print(f"  - GPU {i}: {gpu.name}")
            print("=" * 50 + "\n")
        except Exception:
            pass
    else:
        print("\n" + "=" * 50)
        print("ğŸš€ FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘")
        print("âš  CPU ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ (GPU ë¯¸ì‚¬ìš©)")
        print("=" * 50 + "\n")


# Jinja2 í…œí”Œë¦¿ ì—”ì§„ ì´ˆê¸°í™” (HTML í…œí”Œë¦¿ ë Œë”ë§ìš©)
templates = Jinja2Templates(directory=str(TEMPLATES_DIR))


def _encode_image_with_boxes(
    image_bytes: bytes, detections: Dict[str, Dict[str, object]]
) -> str:
    """
    ê°ì§€ëœ ì–¼êµ´ì— ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë ¤ì„œ base64 ì¸ì½”ë”©ëœ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜.
    
    Args:
        image_bytes: ì›ë³¸ ì´ë¯¸ì§€ì˜ ë°”ì´íŠ¸ ë°ì´í„°
        detections: RetinaFaceê°€ ê°ì§€í•œ ì–¼êµ´ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    
    Returns:
        base64ë¡œ ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë¬¸ìì—´ (HTMLì—ì„œ ì§ì ‘ í‘œì‹œ ê°€ëŠ¥)
    """
    # ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ PIL Image ê°ì²´ë¡œ ë³€í™˜ (RGB í˜•ì‹ìœ¼ë¡œ í†µì¼)
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    # ì´ë¯¸ì§€ì— ê·¸ë¦¼ì„ ê·¸ë¦¬ê¸° ìœ„í•œ Draw ê°ì²´ ìƒì„±
    draw = ImageDraw.Draw(image)

    # ê°ì§€ëœ ê° ì–¼êµ´ì— ëŒ€í•´ ë°”ìš´ë”© ë°•ìŠ¤ì™€ ì ìˆ˜ í‘œì‹œ
    for face in detections.values():
        # ì–¼êµ´ ì˜ì—­ ì¢Œí‘œ ì¶”ì¶œ (x1, y1, x2, y2)
        area = face.get("facial_area") if isinstance(face, dict) else None
        if not area or len(area) != 4:
            continue
        x1, y1, x2, y2 = area
        # ì´ˆë¡ìƒ‰ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë‘ê»˜ 3í”½ì…€)
        draw.rectangle([(x1, y1), (x2, y2)], outline="#00FF00", width=3)
        # ì–¼êµ´ ê°ì§€ ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ì¶œ
        score = face.get("score") if isinstance(face, dict) else None
        if score:
            # ì ìˆ˜ë¥¼ ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€ í‘œì‹œ
            label = f"{float(score):.2f}"
            label_x = x1 + 4  # ë°•ìŠ¤ ì™¼ìª½ ìƒë‹¨ì—ì„œ ì•½ê°„ ì˜¤ë¥¸ìª½ìœ¼ë¡œ
            label_y = y1 + 4  # ë°•ìŠ¤ ì™¼ìª½ ìƒë‹¨ì—ì„œ ì•½ê°„ ì•„ë˜ë¡œ
            # ì ìˆ˜ í…ìŠ¤íŠ¸ë¥¼ ì´ˆë¡ìƒ‰ìœ¼ë¡œ í‘œì‹œ
            draw.text((label_x, label_y), label, fill="#00FF00")

    # ì´ë¯¸ì§€ë¥¼ JPEG í˜•ì‹ìœ¼ë¡œ ë©”ëª¨ë¦¬ ë²„í¼ì— ì €ì¥
    buffer = io.BytesIO()
    image.save(buffer, format="JPEG")
    # ë²„í¼ì˜ ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ base64 ë¬¸ìì—´ë¡œ ì¸ì½”ë”© (HTML img íƒœê·¸ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
    encoded = base64.b64encode(buffer.getvalue()).decode("utf-8")
    return encoded


@app.get("/", response_class=HTMLResponse)
async def index(request: Request) -> HTMLResponse:
    """
    ë©”ì¸ í˜ì´ì§€ ì—”ë“œí¬ì¸íŠ¸.
    ì‚¬ìš©ìê°€ ì²˜ìŒ ì ‘ì†í•˜ê±°ë‚˜ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤.
    ë¹ˆ ìƒíƒœì˜ ì—…ë¡œë“œ í¼ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
    """
    # index.html í…œí”Œë¦¿ì„ ë Œë”ë§í•˜ì—¬ ë°˜í™˜
    # ì´ˆê¸° ìƒíƒœì´ë¯€ë¡œ ê²°ê³¼ ì´ë¯¸ì§€ì™€ ì–¼êµ´ ê°œìˆ˜ëŠ” Noneìœ¼ë¡œ ì„¤ì •
    return templates.TemplateResponse(
        "index.html",
        {
            "request": request,
            "result_image": None,
            "message": "ì´ë¯¸ì§€ ë˜ëŠ” ì˜ìƒì„ ì—…ë¡œë“œí•´ì„œ ì–¼êµ´ì„ ê°ì§€í•´ ë³´ì„¸ìš”.",
            "faces_found": None,
            "result_video": None,
            "total_frames": None,
            "frames_with_faces": None,
            "processing_time": None,
        },
    )


@app.post("/detect", response_class=HTMLResponse)
async def detect_faces(request: Request, file: UploadFile = File(...)) -> HTMLResponse:
    """
    ì–¼êµ´ ê°ì§€ ì—”ë“œí¬ì¸íŠ¸.
    ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ íŒŒì¼ì„ ë°›ì•„ì„œ RetinaFaceë¡œ ì–¼êµ´ì„ ê°ì§€í•˜ê³ ,
    ê²°ê³¼ ì´ë¯¸ì§€ì™€ í•¨ê»˜ HTML í˜ì´ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # ê²°ê³¼ ë©”ì‹œì§€, ì¸ì½”ë”©ëœ ì´ë¯¸ì§€, ê°ì§€ëœ ì–¼êµ´ ê°œìˆ˜ë¥¼ ì €ì¥í•  ë³€ìˆ˜ ì´ˆê¸°í™”
    message: Optional[str] = None
    result_image: Optional[str] = None
    faces_found: Optional[int] = None

    # ì—…ë¡œë“œëœ íŒŒì¼ì˜ ë°”ì´íŠ¸ ë°ì´í„° ì½ê¸°
    contents = await file.read()
    if not contents:
        # íŒŒì¼ì´ ë¹„ì–´ìˆìœ¼ë©´ ì—ëŸ¬ ë©”ì‹œì§€ ì„¤ì •
        message = "ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
    else:
        temp_path = None
        try:
            # RetinaFaceëŠ” íŒŒì¼ ê²½ë¡œë¥¼ í•„ìš”ë¡œ í•˜ë¯€ë¡œ ì„ì‹œ íŒŒì¼ ìƒì„±
            # ì›ë³¸ íŒŒì¼ í™•ì¥ìë¥¼ ìœ ì§€í•˜ì—¬ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬
            with NamedTemporaryFile(delete=False, suffix=Path(file.filename).suffix) as tmp:
                tmp.write(contents)
                temp_path = tmp.name

            # RetinaFaceë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ ê°ì§€ ìˆ˜í–‰
            detections = RetinaFace.detect_faces(temp_path)
            if isinstance(detections, dict) and detections:
                # ì–¼êµ´ì´ ê°ì§€ëœ ê²½ìš°
                faces_found = len(detections)
                # ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
                result_image = _encode_image_with_boxes(contents, detections)
                message = f"ì´ {faces_found}ê°œì˜ ì–¼êµ´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."
            else:
                # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì€ ê²½ìš°
                message = "ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”."
        except Exception as exc:  # pragma: no cover - runtime safeguard
            # ì˜ˆì™¸ ë°œìƒ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì„¤ì •
            message = f"ê°ì§€ ë„ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}"
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
            if temp_path and os.path.exists(temp_path):
                os.remove(temp_path)

    # ê²°ê³¼ë¥¼ í¬í•¨í•œ HTML í˜ì´ì§€ ë°˜í™˜
    return templates.TemplateResponse(
        "index.html",
        {
            "request": request,
            "result_image": result_image,
            "message": message,
            "faces_found": faces_found,
            "result_video": None,
        },
    )


@app.get("/detect_example_image", response_class=HTMLResponse)
async def detect_example_image(request: Request) -> HTMLResponse:
    """
    ì˜ˆì‹œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•œ ì–¼êµ´ ê°ì§€ ì—”ë“œí¬ì¸íŠ¸.
    data/newjeans.jpg íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ ê°ì§€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    # ê²°ê³¼ ë©”ì‹œì§€, ì¸ì½”ë”©ëœ ì´ë¯¸ì§€, ê°ì§€ëœ ì–¼êµ´ ê°œìˆ˜ë¥¼ ì €ì¥í•  ë³€ìˆ˜ ì´ˆê¸°í™”
    message: Optional[str] = None
    result_image: Optional[str] = None
    faces_found: Optional[int] = None

    # ì˜ˆì‹œ ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not EXAMPLE_IMAGE_PATH.exists():
        message = f"ì˜ˆì‹œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {EXAMPLE_IMAGE_PATH}"
    else:
        try:
            # ì˜ˆì‹œ ì´ë¯¸ì§€ íŒŒì¼ ì½ê¸°
            with open(EXAMPLE_IMAGE_PATH, "rb") as f:
                contents = f.read()

            # RetinaFaceë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ ê°ì§€ ìˆ˜í–‰
            detections = RetinaFace.detect_faces(str(EXAMPLE_IMAGE_PATH))
            if isinstance(detections, dict) and detections:
                # ì–¼êµ´ì´ ê°ì§€ëœ ê²½ìš°
                faces_found = len(detections)
                # ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
                result_image = _encode_image_with_boxes(contents, detections)
                message = f"ì˜ˆì‹œ ì´ë¯¸ì§€ì—ì„œ ì´ {faces_found}ê°œì˜ ì–¼êµ´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."
            else:
                # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì€ ê²½ìš°
                message = "ì˜ˆì‹œ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        except Exception as exc:
            # ì˜ˆì™¸ ë°œìƒ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì„¤ì •
            message = f"ì˜ˆì‹œ ì´ë¯¸ì§€ ì²˜ë¦¬ ë„ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}"

    # ê²°ê³¼ë¥¼ í¬í•¨í•œ HTML í˜ì´ì§€ ë°˜í™˜
    return templates.TemplateResponse(
        "index.html",
        {
            "request": request,
            "result_image": result_image,
            "message": message,
            "faces_found": faces_found,
            "result_video": None,
        },
    )


def _draw_boxes_on_frame(
    frame: np.ndarray, detections: Dict[str, Dict[str, object]]
) -> np.ndarray:
    """
    í”„ë ˆì„ì— ê°ì§€ëœ ì–¼êµ´ì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜.
    
    Args:
        frame: OpenCVë¡œ ì½ì€ í”„ë ˆì„ (numpy ë°°ì—´, BGR í˜•ì‹)
        detections: RetinaFaceê°€ ê°ì§€í•œ ì–¼êµ´ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    
    Returns:
        ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ í”„ë ˆì„
    """
    # í”„ë ˆì„ ë³µì‚¬ (ì›ë³¸ ë³´ì¡´)
    result_frame = frame.copy()
    
    # ê°ì§€ëœ ê° ì–¼êµ´ì— ëŒ€í•´ ë°”ìš´ë”© ë°•ìŠ¤ì™€ ì ìˆ˜ í‘œì‹œ
    for face in detections.values():
        # ì–¼êµ´ ì˜ì—­ ì¢Œí‘œ ì¶”ì¶œ (x1, y1, x2, y2)
        area = face.get("facial_area") if isinstance(face, dict) else None
        if not area or len(area) != 4:
            continue
        x1, y1, x2, y2 = map(int, area)
        
        # ì´ˆë¡ìƒ‰ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (BGR í˜•ì‹: (0, 255, 0))
        cv2.rectangle(result_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
        
        # ì–¼êµ´ ê°ì§€ ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ì¶œ
        score = face.get("score") if isinstance(face, dict) else None
        if score:
            # ì ìˆ˜ë¥¼ ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€ í‘œì‹œ
            label = f"{float(score):.2f}"
            # í…ìŠ¤íŠ¸ ë°°ê²½ì„ ìœ„í•œ ì¢Œí‘œ ê³„ì‚°
            label_x = x1 + 4
            label_y = y1 - 20 if y1 > 20 else y1 + 20
            # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸° (ê°€ë…ì„± í–¥ìƒ)
            (text_width, text_height), _ = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
            )
            cv2.rectangle(
                result_frame,
                (label_x - 2, label_y - text_height - 2),
                (label_x + text_width + 2, label_y + 2),
                (0, 255, 0),
                -1,
            )
            # ì ìˆ˜ í…ìŠ¤íŠ¸ë¥¼ ê²€ì€ìƒ‰ìœ¼ë¡œ í‘œì‹œ
            cv2.putText(
                result_frame,
                label,
                (label_x, label_y),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 0, 0),
                2,
            )
    
    return result_frame


def _process_video(
    video_path: str, output_path: str
) -> tuple[int, int, float]:
    """
    ì˜ìƒì˜ ê° í”„ë ˆì„ì— ëŒ€í•´ ì–¼êµ´ ê°ì§€ë¥¼ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ ì˜ìƒì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    
    Args:
        video_path: ì…ë ¥ ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        output_path: ì¶œë ¥ ì˜ìƒ íŒŒì¼ ê²½ë¡œ
    
    Returns:
        (ì´ í”„ë ˆì„ ìˆ˜, ê°ì§€ëœ ì–¼êµ´ì´ ìˆëŠ” í”„ë ˆì„ ìˆ˜, ì²˜ë¦¬ ì‹œê°„(ì´ˆ)) íŠœí”Œ
    """
    # ì˜ìƒ íŒŒì¼ ì—´ê¸°
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError("ì˜ìƒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # ì¶œë ¥ ì˜ìƒ ì‘ì„±ì ì´ˆê¸°í™”
    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    frames_with_faces = 0
    frame_count = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # ì„ì‹œ íŒŒì¼ì— í”„ë ˆì„ ì €ì¥ (RetinaFaceëŠ” íŒŒì¼ ê²½ë¡œë¥¼ í•„ìš”ë¡œ í•¨)
            temp_frame_path = None
            try:
                with NamedTemporaryFile(delete=False, suffix=".jpg") as tmp:
                    temp_frame_path = tmp.name
                    cv2.imwrite(temp_frame_path, frame)
                
                # RetinaFaceë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ ê°ì§€ ìˆ˜í–‰
                detections = RetinaFace.detect_faces(temp_frame_path)
                
                if isinstance(detections, dict) and detections:
                    # ì–¼êµ´ì´ ê°ì§€ëœ ê²½ìš° ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                    frame = _draw_boxes_on_frame(frame, detections)
                    frames_with_faces += 1
                
                # ì²˜ë¦¬ëœ í”„ë ˆì„ì„ ì¶œë ¥ ì˜ìƒì— ì‘ì„±
                out.write(frame)
                
            finally:
                # ì„ì‹œ í”„ë ˆì„ íŒŒì¼ ì •ë¦¬
                if temp_frame_path and os.path.exists(temp_frame_path):
                    os.remove(temp_frame_path)
    
    finally:
        # ë¦¬ì†ŒìŠ¤ í•´ì œ
        cap.release()
        out.release()
    
    return total_frames, frames_with_faces, frame_count / fps if fps > 0 else 0


@app.post("/detect_video", response_class=HTMLResponse)
async def detect_faces_in_video(
    request: Request, file: UploadFile = File(...)
) -> HTMLResponse:
    """
    ì˜ìƒ ì–¼êµ´ ê°ì§€ ì—”ë“œí¬ì¸íŠ¸.
    ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì˜ìƒ íŒŒì¼ì„ ë°›ì•„ì„œ ê° í”„ë ˆì„ì— ëŒ€í•´ RetinaFaceë¡œ ì–¼êµ´ì„ ê°ì§€í•˜ê³ ,
    ê²°ê³¼ ì˜ìƒì„ ìƒì„±í•˜ì—¬ ë‹¤ìš´ë¡œë“œ ë§í¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    message: Optional[str] = None
    result_video: Optional[str] = None
    total_frames: Optional[int] = None
    frames_with_faces: Optional[int] = None
    processing_time: Optional[float] = None
    
    # ì—…ë¡œë“œëœ íŒŒì¼ì˜ ë°”ì´íŠ¸ ë°ì´í„° ì½ê¸°
    contents = await file.read()
    if not contents:
        message = "ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
    else:
        input_path = None
        output_path = None
        try:
            # ì…ë ¥ ì˜ìƒ ì„ì‹œ íŒŒì¼ ìƒì„±
            input_suffix = Path(file.filename).suffix or ".mp4"
            with NamedTemporaryFile(delete=False, suffix=input_suffix) as tmp:
                tmp.write(contents)
                input_path = tmp.name
            
            # ì¶œë ¥ ì˜ìƒ ì„ì‹œ íŒŒì¼ ìƒì„±
            with NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
                output_path = tmp.name
            
            # ì˜ìƒ ì²˜ë¦¬ ìˆ˜í–‰
            total_frames, frames_with_faces, processing_time = _process_video(
                input_path, output_path
            )
            
            # ê²°ê³¼ ì˜ìƒì„ base64ë¡œ ì¸ì½”ë”©
            with open(output_path, "rb") as f:
                video_bytes = f.read()
                result_video = base64.b64encode(video_bytes).decode("utf-8")
            
            message = (
                f"ì²˜ë¦¬ ì™„ë£Œ! ì´ {total_frames}ê°œ í”„ë ˆì„ ì¤‘ "
                f"{frames_with_faces}ê°œ í”„ë ˆì„ì—ì„œ ì–¼êµ´ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤. "
                f"(ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ)"
            )
            
        except Exception as exc:
            message = f"ì˜ìƒ ì²˜ë¦¬ ë„ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}"
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if input_path and os.path.exists(input_path):
                os.remove(input_path)
            if output_path and os.path.exists(output_path):
                os.remove(output_path)
    
    # ê²°ê³¼ë¥¼ í¬í•¨í•œ HTML í˜ì´ì§€ ë°˜í™˜
    return templates.TemplateResponse(
        "index.html",
        {
            "request": request,
            "result_image": None,
            "message": message,
            "faces_found": None,
            "result_video": result_video,
            "total_frames": total_frames,
            "frames_with_faces": frames_with_faces,
            "processing_time": processing_time,
        },
    )


@app.get("/detect_example_video", response_class=HTMLResponse)
async def detect_example_video(request: Request) -> HTMLResponse:
    """
    ì˜ˆì‹œ ì˜ìƒì„ ì‚¬ìš©í•œ ì–¼êµ´ ê°ì§€ ì—”ë“œí¬ì¸íŠ¸.
    data/video.mp4 íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ê° í”„ë ˆì„ì— ëŒ€í•´ ì–¼êµ´ ê°ì§€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    message: Optional[str] = None
    result_video: Optional[str] = None
    total_frames: Optional[int] = None
    frames_with_faces: Optional[int] = None
    processing_time: Optional[float] = None

    # ì˜ˆì‹œ ì˜ìƒ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not EXAMPLE_VIDEO_PATH.exists():
        message = f"ì˜ˆì‹œ ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {EXAMPLE_VIDEO_PATH}"
    else:
        output_path = None
        try:
            # ì¶œë ¥ ì˜ìƒ ì„ì‹œ íŒŒì¼ ìƒì„±
            with NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
                output_path = tmp.name

            # ì˜ìƒ ì²˜ë¦¬ ìˆ˜í–‰
            total_frames, frames_with_faces, processing_time = _process_video(
                str(EXAMPLE_VIDEO_PATH), output_path
            )

            # ê²°ê³¼ ì˜ìƒì„ base64ë¡œ ì¸ì½”ë”©
            with open(output_path, "rb") as f:
                video_bytes = f.read()
                result_video = base64.b64encode(video_bytes).decode("utf-8")

            message = (
                f"ì˜ˆì‹œ ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ! ì´ {total_frames}ê°œ í”„ë ˆì„ ì¤‘ "
                f"{frames_with_faces}ê°œ í”„ë ˆì„ì—ì„œ ì–¼êµ´ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤. "
                f"(ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ)"
            )

        except Exception as exc:
            message = f"ì˜ˆì‹œ ì˜ìƒ ì²˜ë¦¬ ë„ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}"
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if output_path and os.path.exists(output_path):
                os.remove(output_path)

    # ê²°ê³¼ë¥¼ í¬í•¨í•œ HTML í˜ì´ì§€ ë°˜í™˜
    return templates.TemplateResponse(
        "index.html",
        {
            "request": request,
            "result_image": None,
            "message": message,
            "faces_found": None,
            "result_video": result_video,
            "total_frames": total_frames,
            "frames_with_faces": frames_with_faces,
            "processing_time": processing_time,
        },
    )
