"""
RetinaFace ì–¼êµ´ ê²€ì¶œ ëª¨ë¸
InsightFaceì˜ RetinaFace ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ì„ ê²€ì¶œí•©ë‹ˆë‹¤.
"""

import cv2
import numpy as np
import logging
import base64
from typing import List, Tuple, Optional, Dict, Any
from datetime import datetime

try:
    import insightface
    from insightface.app import FaceAnalysis
    INSIGHTFACE_AVAILABLE = True
except ImportError:
    INSIGHTFACE_AVAILABLE = False
    print("âš ï¸ InsightFaceê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤í… ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

class FaceDetector:
    """RetinaFace ê¸°ë°˜ ì–¼êµ´ ê²€ì¶œ í´ë˜ìŠ¤ (BentoML ì—°ë™ ì§€ì›)"""
    
    def __init__(self, model_name='buffalo_l', ctx_id=0, stub_mode=None):
        """
        FaceDetector ì´ˆê¸°í™”
        
        Args:
            model_name (str): ì‚¬ìš©í•  InsightFace ëª¨ë¸ëª… ('buffalo_l', 'buffalo_m', 'buffalo_s')
            ctx_id (int): GPU ID (0: GPU, -1: CPU)
            stub_mode (bool): ìŠ¤í… ëª¨ë“œ ê°•ì œ ì„¤ì • (None: ìë™ ê°ì§€)
        """
        self.model_name = model_name
        self.ctx_id = ctx_id
        self.app = None
        self.detection_size = (640, 640)  # ê²€ì¶œì„ ìœ„í•œ ì´ë¯¸ì§€ í¬ê¸°
        self.logger = logging.getLogger(__name__)
        
        # ìŠ¤í… ëª¨ë“œ ì„¤ì •
        if stub_mode is None:
            self.stub_mode = not INSIGHTFACE_AVAILABLE
        else:
            self.stub_mode = stub_mode
            
        self.initialized = False
        self._initialize_model()
    
    def _initialize_model(self):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            if self.stub_mode:
                print(f"ğŸ”§ FaceDetector ìŠ¤í… ëª¨ë“œë¡œ ì´ˆê¸°í™” ì¤‘...")
                self.app = None
                self.initialized = True
                print("âœ… FaceDetector ìŠ¤í… ëª¨ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
                return
                
            print(f"ğŸ”§ RetinaFace ëª¨ë¸ ë¡œë”© ì¤‘... (ëª¨ë¸: {self.model_name})")
            
            # InsightFace FaceAnalysis ì•± ì´ˆê¸°í™”
            self.app = FaceAnalysis(
                name=self.model_name,
                allowed_modules=['detection']  # ê²€ì¶œë§Œ ì‚¬ìš©
            )
            
            # ëª¨ë¸ ì¤€ë¹„ (ì²« ì‹¤í–‰ì‹œ ìë™ìœ¼ë¡œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ)
            self.app.prepare(ctx_id=self.ctx_id, det_size=self.detection_size)
            
            self.initialized = True
            print("âœ… RetinaFace ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"RetinaFace ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            print(f"âŒ RetinaFace ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨, ìŠ¤í… ëª¨ë“œë¡œ ì „í™˜: {str(e)}")
            self.stub_mode = True
            self.app = None
            self.initialized = True
    
    def detect_faces(self, image, confidence_threshold=0.5):
        """
        ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ê²€ì¶œ
        
        Args:
            image (np.ndarray): ì…ë ¥ ì´ë¯¸ì§€ (BGR í˜•ì‹)
            confidence_threshold (float): ê²€ì¶œ ì‹ ë¢°ë„ ì„ê³„ê°’
            
        Returns:
            list: ê²€ì¶œëœ ì–¼êµ´ ì •ë³´ ë¦¬ìŠ¤íŠ¸
                  ê° ì›ì†ŒëŠ” (bbox, landmarks, confidence) íŠœí”Œ
        """
        if not self.initialized:
            raise RuntimeError("ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        # ìŠ¤í… ëª¨ë“œì¸ ê²½ìš° ë”ë¯¸ ë°ì´í„° ë°˜í™˜
        if self.stub_mode:
            return self._generate_stub_detections(image, confidence_threshold)
            
        try:
            # RGB ë³€í™˜ (InsightFaceëŠ” RGB ì…ë ¥ì„ ê¸°ëŒ€)
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # ì–¼êµ´ ê²€ì¶œ ì‹¤í–‰
            faces = self.app.get(rgb_image)
            
            results = []
            for face in faces:
                # ê²€ì¶œ ì‹ ë¢°ë„ í™•ì¸
                if hasattr(face, 'det_score') and face.det_score < confidence_threshold:
                    continue
                
                # ë°”ìš´ë”© ë°•ìŠ¤ (x1, y1, x2, y2)
                bbox = face.bbox.astype(int)
                
                # ì–¼êµ´ ëœë“œë§ˆí¬ (5ê°œ ì : ì–‘ìª½ ëˆˆ, ì½”ë, ì–‘ìª½ ì…ê¼¬ë¦¬)
                landmarks = face.kps if hasattr(face, 'kps') else None
                
                # ê²€ì¶œ ì‹ ë¢°ë„
                confidence = face.det_score if hasattr(face, 'det_score') else 1.0
                
                results.append((bbox, landmarks, confidence))
            
            return results
            
        except Exception as e:
            self.logger.error(f"ì–¼êµ´ ê²€ì¶œ ì˜¤ë¥˜: {str(e)}")
            print(f"âŒ ì–¼êµ´ ê²€ì¶œ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def detect_largest_face(self, image, confidence_threshold=0.5):
        """
        ì´ë¯¸ì§€ì—ì„œ ê°€ì¥ í° ì–¼êµ´ í•˜ë‚˜ë§Œ ê²€ì¶œ
        
        Args:
            image (np.ndarray): ì…ë ¥ ì´ë¯¸ì§€
            confidence_threshold (float): ê²€ì¶œ ì‹ ë¢°ë„ ì„ê³„ê°’
            
        Returns:
            tuple or None: (bbox, landmarks, confidence) ë˜ëŠ” None
        """
        faces = self.detect_faces(image, confidence_threshold)
        
        if not faces:
            return None
        
        # ë©´ì  ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
        largest_face = max(faces, key=lambda f: (f[0][2] - f[0][0]) * (f[0][3] - f[0][1]))
        
        return largest_face
    
    def crop_face(self, image, bbox, margin=20):
        """
        ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì–¼êµ´ ì˜ì—­ í¬ë¡­
        
        Args:
            image (np.ndarray): ì…ë ¥ ì´ë¯¸ì§€
            bbox (np.ndarray): ë°”ìš´ë”© ë°•ìŠ¤ [x1, y1, x2, y2]
            margin (int): í¬ë¡­ ì—¬ë°±
            
        Returns:
            np.ndarray: í¬ë¡­ëœ ì–¼êµ´ ì´ë¯¸ì§€
        """
        h, w = image.shape[:2]
        
        x1, y1, x2, y2 = bbox
        
        # ì—¬ë°± ì¶”ê°€
        x1 = max(0, x1 - margin)
        y1 = max(0, y1 - margin)
        x2 = min(w, x2 + margin)
        y2 = min(h, y2 + margin)
        
        return image[y1:y2, x1:x2]
    
    def draw_detections(self, image, faces, draw_landmarks=True):
        """
        ê²€ì¶œ ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°
        
        Args:
            image (np.ndarray): ì…ë ¥ ì´ë¯¸ì§€
            faces (list): ê²€ì¶œëœ ì–¼êµ´ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            draw_landmarks (bool): ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸° ì—¬ë¶€
            
        Returns:
            np.ndarray: ê²€ì¶œ ê²°ê³¼ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€
        """
        result_image = image.copy()
        
        for bbox, landmarks, confidence in faces:
            x1, y1, x2, y2 = bbox
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # ì‹ ë¢°ë„ í…ìŠ¤íŠ¸
            confidence_text = f'{confidence:.2f}'
            cv2.putText(result_image, confidence_text, (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
            if draw_landmarks and landmarks is not None:
                for point in landmarks:
                    x, y = point.astype(int)
                    cv2.circle(result_image, (x, y), 2, (255, 0, 0), -1)
        
        return result_image
    
    def set_detection_size(self, size):
        """
        ê²€ì¶œì„ ìœ„í•œ ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° ì„¤ì •
        
        Args:
            size (tuple): (width, height)
        """
        self.detection_size = size
        if self.app:
            self.app.prepare(ctx_id=self.ctx_id, det_size=size)
    
    def _generate_stub_detections(self, image, confidence_threshold):
        """
        ìŠ¤í… ëª¨ë“œìš© ë”ë¯¸ ì–¼êµ´ ê²€ì¶œ ê²°ê³¼ ìƒì„±
        
        Args:
            image (np.ndarray): ì…ë ¥ ì´ë¯¸ì§€
            confidence_threshold (float): ì‹ ë¢°ë„ ì„ê³„ê°’
            
        Returns:
            list: ë”ë¯¸ ê²€ì¶œ ê²°ê³¼
        """
        h, w = image.shape[:2]
        
        # ì´ë¯¸ì§€ ì¤‘ì•™ì— ë”ë¯¸ ì–¼êµ´ ë°”ìš´ë”© ë°•ìŠ¤ ìƒì„±
        center_x, center_y = w // 2, h // 2
        face_size = min(w, h) // 4
        
        x1 = max(0, center_x - face_size // 2)
        y1 = max(0, center_y - face_size // 2)
        x2 = min(w, center_x + face_size // 2)
        y2 = min(h, center_y + face_size // 2)
        
        bbox = np.array([x1, y1, x2, y2])
        
        # ë”ë¯¸ ëœë“œë§ˆí¬ (5ê°œ ì )
        landmarks = np.array([
            [center_x - 20, center_y - 10],  # ì™¼ìª½ ëˆˆ
            [center_x + 20, center_y - 10],  # ì˜¤ë¥¸ìª½ ëˆˆ
            [center_x, center_y],            # ì½”ë
            [center_x - 10, center_y + 20],  # ì™¼ìª½ ì…ê¼¬ë¦¬
            [center_x + 10, center_y + 20]   # ì˜¤ë¥¸ìª½ ì…ê¼¬ë¦¬
        ], dtype=np.float32)
        
        confidence = 0.85  # ë”ë¯¸ ì‹ ë¢°ë„
        
        if confidence >= confidence_threshold:
            return [(bbox, landmarks, confidence)]
        else:
            return []
    
    def detect_faces_from_base64(self, image_base64: str, confidence_threshold=0.5):
        """
        Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ê²€ì¶œ (BentoML API í˜¸í™˜)
        
        Args:
            image_base64 (str): Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
            confidence_threshold (float): ê²€ì¶œ ì‹ ë¢°ë„ ì„ê³„ê°’
            
        Returns:
            Dict: ê²€ì¶œ ê²°ê³¼
        """
        try:
            # Base64 ë””ì½”ë”©
            image_data = base64.b64decode(image_base64)
            nparr = np.frombuffer(image_data, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                return {
                    "success": False,
                    "error": "ì´ë¯¸ì§€ ë””ì½”ë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                }
            
            # ì–¼êµ´ ê²€ì¶œ
            faces = self.detect_faces(image, confidence_threshold)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_faces = []
            for bbox, landmarks, confidence in faces:
                face_info = {
                    "bbox": bbox.tolist(),
                    "landmarks": landmarks.tolist() if landmarks is not None else None,
                    "confidence": float(confidence)
                }
                formatted_faces.append(face_info)
            
            return {
                "success": True,
                "detected_faces": formatted_faces,
                "total_faces": len(formatted_faces),
                "image_size": {"width": image.shape[1], "height": image.shape[0]},
                "processing_time_ms": 0,  # TODO: ì‹¤ì œ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
                "model_info": self.get_model_info()
            }
            
        except Exception as e:
            self.logger.error(f"Base64 ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "success": False,
                "error": f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
    
    def get_model_info(self):
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            'model_name': self.model_name,
            'detection_size': self.detection_size,
            'ctx_id': self.ctx_id,
            'initialized': self.initialized,
            'stub_mode': self.stub_mode,
            'insightface_available': INSIGHTFACE_AVAILABLE,
            'version': '2.0.0-bentoml'
        }


# í…ŒìŠ¤íŠ¸ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
def test_face_detector():
    """FaceDetector í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ”§ FaceDetector í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # ìŠ¤í… ëª¨ë“œë¡œ í…ŒìŠ¤íŠ¸
    detector = FaceDetector(stub_mode=True)
    print(f"ëª¨ë¸ ì •ë³´: {detector.get_model_info()}")
    
    # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
    dummy_image = np.zeros((480, 640, 3), dtype=np.uint8)
    faces = detector.detect_faces(dummy_image)
    print(f"ê²€ì¶œëœ ì–¼êµ´ ìˆ˜: {len(faces)}")
    
    if faces:
        bbox, landmarks, confidence = faces[0]
        print(f"ì²« ë²ˆì§¸ ì–¼êµ´ - bbox: {bbox}, confidence: {confidence}")
    
    print("âœ… FaceDetector í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    return detector

def create_face_detector_for_bentoml():
    """BentoMLìš© FaceDetector ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    try:
        # ì‹¤ì œ ëª¨ë¸ ì‹œë„
        detector = FaceDetector(stub_mode=False)
        print("âœ… ì‹¤ì œ InsightFace ëª¨ë¸ë¡œ FaceDetector ì´ˆê¸°í™” ì™„ë£Œ")
        return detector
    except Exception as e:
        print(f"âš ï¸ ì‹¤ì œ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨, ìŠ¤í… ëª¨ë“œë¡œ ì „í™˜: {e}")
        # ìŠ¤í… ëª¨ë“œë¡œ í´ë°±
        detector = FaceDetector(stub_mode=True)
        print("âœ… ìŠ¤í… ëª¨ë“œë¡œ FaceDetector ì´ˆê¸°í™” ì™„ë£Œ")
        return detector

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    test_detector = test_face_detector()
    
    # ì›¹ìº  í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­ - ìŠ¤í… ëª¨ë“œê°€ ì•„ë‹ ë•Œë§Œ)
    if not test_detector.stub_mode:
        print("\nì‹¤ì œ ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ì›¹ìº  í…ŒìŠ¤íŠ¸ë¥¼ ì›í•˜ì‹œë©´ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.")
        # cap = cv2.VideoCapture(0)
        # while True:
        #     ret, frame = cap.read()
        #     if not ret:
        #         break
        #         
        #     faces = test_detector.detect_faces(frame)
        #     result = test_detector.draw_detections(frame, faces)
        #     
        #     cv2.imshow('Face Detection', result)
        #     if cv2.waitKey(1) & 0xFF == ord('q'):
        #         break
        # 
        # cap.release()
        # cv2.destroyAllWindows()
    
    print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")